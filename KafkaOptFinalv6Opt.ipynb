{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/usr/local/Cellar/apache-spark/3.1.2/libexec\")\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import*\n",
    "from pyspark.sql.types import*\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd \n",
    "import traceback\n",
    "import sys\n",
    "from time import sleep\n",
    "import traceback\n",
    "import smtplib\n",
    "from collections import defaultdict\n",
    "\n",
    "import ibm_db\n",
    "import ibm_db_dbi\n",
    "import ibm_db_sa\n",
    "from datetime import datetime, date, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "\n",
    "import logging\n",
    "logger = spark._jvm.org.apache.log4j\n",
    "logging.getLogger(\"py4j.java_gateway\").setLevel(logging.ERROR)\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######## Grab the Arguments #########\n",
    "\n",
    "print(\"**Arg*****\")\n",
    "argslist = sys.argv\n",
    "print(\"********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Function to Send Email #########\n",
    "\n",
    "def sendmail(sub, body):\n",
    "    try:\n",
    "       SERVER = \"us.relay.ibm.com\"\n",
    "       #SERVER = \"smtp.gmail.com\"\n",
    "       #SERVER = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "       #SERVER.ehlo()\n",
    "       FROM = \"romdbload@radial.com\"\n",
    "       TO = [\"mlakshm@us.ibm.com\"] # must be a list\n",
    "       SUBJECT = sub\n",
    "       TEXT = body\n",
    "       message = 'From:'+FROM+       '\\nTo: '+\", \".join(TO)+       '\\nSubject: '+SUBJECT+'\\n'+TEXT\n",
    "       print(message)\n",
    "       server = smtplib.SMTP(SERVER)\n",
    "       server.sendmail(FROM, TO, message)\n",
    "       server.quit()\n",
    "       return 0\n",
    "    except Exception as e:\n",
    "       exp_tb=traceback.format_exc()\n",
    "       print(exp_tb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tbllist=[]\n",
    "jsonpathlists=[]\n",
    "colslist=[]\n",
    "json_exploded_path_lists=[]\n",
    "col_len_lists=[]\n",
    "\n",
    "with open('json_column_map_updated_newest.txt') as f:\n",
    "    contents = f.read()\n",
    "    contents=contents.strip()\n",
    "    maplist=contents.split(\"TABLE_NAME:\")\n",
    "    #print(maplist)\n",
    "    #maplist = list(filter([], maplist))\n",
    "    for lmap in maplist:\n",
    "        \n",
    "        lmaplist=lmap.split(\"\\n\")\n",
    "        #lmaplist = list(filter(None, lmaplist))\n",
    "        tbl=lmaplist.pop(0)\n",
    "        tbllist.append(tbl)\n",
    "        collist=[]\n",
    "        jsonpathlist=[]\n",
    "        json_exploded_path_list=[]\n",
    "        col_len_list=[]\n",
    "        \n",
    "        for col_json in lmaplist:\n",
    "            coljsonarr=col_json.split(\",\")\n",
    "            if (len(coljsonarr)==4):\n",
    "               collist.append(coljsonarr[0])\n",
    "               jsonpathlist.append(coljsonarr[1])\n",
    "               json_exploded_path_list.append(coljsonarr[2])\n",
    "               col_len_list.append(coljsonarr[3])\n",
    "               \n",
    "                \n",
    "        colslist.append(collist)\n",
    "        jsonpathlists.append(jsonpathlist)\n",
    "        json_exploded_path_lists.append(json_exploded_path_list)\n",
    "        col_len_lists.append(col_len_list)\n",
    "            \n",
    "            \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tbllist = [x for x in tbllist if x != 'KAFKARADIAL.']\n",
    "tbllist = [x for x in tbllist if x != '']\n",
    "colslist = [x for x in colslist if x != []]\n",
    "jsonpathlists = [x for x in jsonpathlists if x != []]\n",
    "json_exploded_path_lists = [x for x in json_exploded_path_lists if x != []]\n",
    "col_len_lists = [x for x in col_len_lists if x != []]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(tbllist)\n",
    "print(colslist)\n",
    "print(jsonpathlists)\n",
    "print(json_exploded_path_lists)\n",
    "print(col_len_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jdbcURL=\"\"\n",
    "user=\"\"\n",
    "password=\"\"\n",
    "jdbcstr=\"\"\n",
    "kafka_bootstrap_servers=\"\"\n",
    "scram_user=\"\"\n",
    "scram_pass=\"\"\n",
    "truststore_location=\"\"\n",
    "truststore_password=\"\"\n",
    "\n",
    "with open('cfg_info.txt') as f:\n",
    "    \n",
    "    contents = f.read()\n",
    "    contents=contents.strip()\n",
    "    cfg_infolist=contents.split(\"\\n\")\n",
    "    jdbcURL=cfg_infolist[0]\n",
    "    user=cfg_infolist[1]\n",
    "    password=cfg_infolist[2]\n",
    "    jdbcstr=cfg_infolist[3]\n",
    "    kafka_bootstrap_servers=cfg_infolist[4]\n",
    "    scram_user=cfg_infolist[5]\n",
    "    scram_pass=cfg_infolist[6]\n",
    "    truststore_location=cfg_infolist[7]\n",
    "    truststore_password=cfg_infolist[8]\n",
    "    kafkatopic=cfg_infolist[9]\n",
    "    \n",
    "f.close()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jdbcURL)\n",
    "print(user)\n",
    "print(password)\n",
    "print(jdbcstr)\n",
    "print(kafka_bootstrap_servers)\n",
    "print(scram_user)\n",
    "print(scram_pass)\n",
    "print(truststore_location)\n",
    "print(truststore_password)\n",
    "print(kafkatopic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsondf = spark.read.json(\"order_created_test3.json\", multiLine=True)\n",
    "order_created_schema=jsondf.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsondf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsondf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
    "  .option(\"kafka.sasl.jaas.config\",\"org.apache.kafka.common.security.scram.ScramLoginModule required username=\"+scram_user+\" password=\"+scram_pass+\";\") \\\n",
    "  .option(\"kafka.security.protocol\", \"SASL_SSL\") \\\n",
    "  .option(\"kafka.sasl.mechanism\", \"SCRAM-SHA-512\") \\\n",
    "  .option(\"kafka.ssl.truststore.location\",truststore_location) \\\n",
    "  .option(\"kafka.ssl.truststore.password\", truststore_password) \\\n",
    "  .option(\"kafka.ssl.protocol\", \"TLSv1.2\") \\\n",
    "  .option(\"kafka.ssl.enabled.protocols\", \"TLSv1.2\") \\\n",
    "  .option(\"kafka.ssl.endpoint.identification.algorithm\", \"HTTPS\") \\\n",
    "  .option(\"failOnDataLoss\", \"false\") \\\n",
    "  .option(\"assign\", \"\"\"{\"\"\"+kafkatopic+\"\"\"}\"\"\") \\\n",
    "  .load() \\\n",
    "  .select(col(\"partition\").cast(\"string\"),col(\"offset\").cast(\"string\"),col(\"value\").cast(\"string\"),from_json(col(\"value\").cast(\"string\"), order_created_schema))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToSQLWarehouse(jdf,epochId,tbl):\n",
    "    \n",
    "  print(tbl)\n",
    "  #print(df)\n",
    "  print(\"hgjghjgh\")\n",
    "  jdf.show()\n",
    "  print(\"jhghjgjn\")\n",
    "  jdf.write.format(\"jdbc\")   .mode(\"append\")   .option(\"url\", jdbcUrl)   .option(\"dbtable\", tbl)   .option(\"user\", user)   .option(\"password\", password)   .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arraysdf = pd.read_csv(\"arrays_order_created.txt\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explodeDFTest(df):\n",
    "    \n",
    "    #df=df.withColumn(\"order\", df.mvalue.order)\n",
    "    #df=df.withColumn(\"customAttributes\", df.mvalue.customAttributes)\n",
    "    #df=df.withColumn(\"topicName\", df.mvalue.topicName)\n",
    "    #df=df.drop(\"mvalue\")\n",
    "    #df=df.drop(\"value\")\n",
    "    #df.show()\n",
    "    \n",
    "    for i, row in arraysdf.iterrows():\n",
    "    \n",
    "     try:\n",
    "            \n",
    "        json_path_to_explode=row['JSON_PATH_TO_EXPLODE']\n",
    "        json_path_exploded=row['JSON_PATH_EXPLODED']\n",
    "        print(json_path_to_explode)\n",
    "        print(json_path_exploded)\n",
    "    \n",
    "        df=df.withColumn(json_path_exploded,explode_outer(json_path_to_explode))\n",
    "        #df.show()\n",
    "        \n",
    "     except Exception as e:\n",
    "        print(e)\n",
    "        print(json_path_to_explode)\n",
    "        \n",
    "        \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explodeDF(df):\n",
    "    \n",
    "    df=df.withColumn(\"order\", df.mvalue.order)\n",
    "    df=df.withColumn(\"customAttributes\", df.mvalue.customAttributes)\n",
    "    df=df.withColumn(\"topicName\", df.mvalue.topicName)\n",
    "    df=df.drop(\"mvalue\")\n",
    "    #df=df.drop(\"value\")\n",
    "    #df.show()\n",
    "    \n",
    "    for i, row in arraysdf.iterrows():\n",
    "    \n",
    "     try:\n",
    "            \n",
    "        json_path_to_explode=row['JSON_PATH_TO_EXPLODE']\n",
    "        json_path_exploded=row['JSON_PATH_EXPLODED']\n",
    "        print(json_path_to_explode)\n",
    "        print(json_path_exploded)\n",
    "    \n",
    "        df=df.withColumn(json_path_exploded,explode_outer(json_path_to_explode))\n",
    "        #df.show()\n",
    "        \n",
    "     except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectToDB():\n",
    "    #logger.info(\"Connecting to the Database....\")\n",
    "    print(\"Connecting to DB\")\n",
    "    conn=\"\"\n",
    "    try:\n",
    "       array = { ibm_db.SQL_ATTR_AUTOCOMMIT : ibm_db.SQL_AUTOCOMMIT_OFF }\n",
    "       #db2_conn = ibm_db.connect(\"DATABASE=BLUDB;HOSTNAME=10.5.197.84;PORT=30480;PROTOCOL=TCPIP;UID=admin;PWD=B09Y0kZgchfo;\", \"\", \"\", array)\n",
    "       #db2_conn = ibm_db.connect(\"DATABASE=BLUDB;HOSTNAME=9938aec0-8105-433e-8bf9-0fbb7e483086.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud;PORT=32459;PROTOCOL=TCPIP;UID=hyf72343;PWD=oBc1ketTvsdM3kod;SECURITY=SSL\", \"\", \"\", array)\n",
    "       db2_conn = ibm_db.connect(jdbcstr, \"\", \"\", array)\n",
    "       #db2_conn = ibm_db.connect(\"jdbc:db2://67beb010-4100-48d1-a281-7b5af97791aa.bs2ipa7w0uv9tsomi9ig.databases.appdomain.cloud:31815/bludb:sslConnection=true;\", \"a5406f1c\", \"eK1EhADAU7y3W61T\")\n",
    "       print(db2_conn)\n",
    "    \n",
    "       #conn = ibm_db_dbi.Connection(db2_conn)\n",
    "       #conn.set_autocommit(False)\n",
    "    except Exception as e:\n",
    "       exp_tb=traceback.format_exc()\n",
    "       print(exp_tb)\n",
    "       sendmail(\"Error Retrieving Last Run Date\",exp_tb)\n",
    "       \n",
    "    return db2_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popTablesBlkAtomicNew(df, epochId):  #### Bulk Insert\n",
    "      \n",
    "      \n",
    "   #####  Create JDBC Connection #######\n",
    "   print(datetime.now())\n",
    "   conn=connectToDB()\n",
    "      \n",
    "   try:\n",
    "      \n",
    "    if df.rdd.isEmpty():\n",
    "       print(df.rdd.isEmpty)\n",
    "    else:\n",
    "      #df.show()\n",
    "      df=df.withColumnRenamed(\"from_json(CAST(value AS STRING))\", \"mvalue\") \n",
    "      #df.select(col(\"mvalue\").cast(\"string\")).show()\n",
    "      #valchk=NULL\n",
    "      #dfnull=df.filter(col(\"mvalue\").cast(\"string\") == '{null, null, null}')\n",
    "      #df=df.filter(\"mvalue is NOT NULL\")\n",
    "    \n",
    "      #dfnull.show()\n",
    "        \n",
    "      #df=df.filter(col(\"mvalue\").cast(\"string\") != '{null, null, null}')\n",
    "    \n",
    "      #if dfnull.rdd.isEmpty():\n",
    "            \n",
    "      #      print(\"Empty\")\n",
    "            \n",
    "      #else:\n",
    "            \n",
    "      #      nulldflist=dfnull.select(\"value\").collect()\n",
    "            \n",
    "      #      for elm in nulldflist:\n",
    "      #          flist=[]\n",
    "      #          fval=elm[0]\n",
    "      #          fparam=tuple([fval])\n",
    "      #          fqry=\"INSERT INTO KAFKARADIAL.INSERT_FAILED_MSG ( msgvalue ) VALUES (?)\"\n",
    "      #          flist.append([fqry,fparam])\n",
    "      #          insertData(flist,conn)\n",
    "    \n",
    "    \n",
    "     \n",
    "    \n",
    "      if df.rdd.isEmpty():\n",
    "       print(df.rdd.isEmpty)\n",
    "    \n",
    "      else:\n",
    "    \n",
    "         ###### Exploding Dataframe #######\n",
    "         print(\"Starting to Explode Data:........\")\n",
    "         print(datetime.now()) \n",
    "         dfblk=explodeDF(df) \n",
    "         print(\"Finished Exploding Data:........\")\n",
    "         print(datetime.now()) \n",
    "      \n",
    "          \n",
    "         ##### Prepare Blk Dataframe & Insert Queries  #######\n",
    "          \n",
    "         #qlist,finaldflist=prepareData(dfblk,json_exploded_path_lists,colslist,epochId,tbllist)\n",
    "         #qlist,finaldflist,dictlist,colslistup=prepareData(dfblk,json_exploded_path_lists,colslist,col_len_lists,epochId,tbllist)\n",
    "         print(\"Starting to Prepare Data:........\")\n",
    "         print(datetime.now())  \n",
    "         qlist=prepareData(dfblk,json_exploded_path_lists,colslist,col_len_lists,epochId,tbllist)\n",
    "         print(datetime.now())\n",
    "         print(\"Finishing to Prepare Data:.......\")\n",
    "    \n",
    "         #print(qlist)\n",
    "         print(\"*****\")\n",
    "         #print(len(finaldflist))   \n",
    "            \n",
    "         ###### Insert to Tables #######\n",
    "         try:\n",
    "             print(\"Starting to Insert:........\")\n",
    "             print(datetime.now())   \n",
    "             insertData(qlist,conn)\n",
    "             print(datetime.now())\n",
    "             print(\"Finishing to Insert:........\")\n",
    "        \n",
    "         except Exception as e:\n",
    "                \n",
    "             print(e)\n",
    "             exp_tb=traceback.format_exc()\n",
    "             print(exp_tb)\n",
    "                \n",
    "             #performSingleInserts(finaldflist,dictlist,colslistup,epochId,tbllist,conn)\n",
    "            \n",
    "    \n",
    "   except Exception as e:\n",
    "          print(\"here...........\")\n",
    "          print(e)\n",
    "          exp_tb=traceback.format_exc()\n",
    "          print(exp_tb)\n",
    "          #popTablesAtomicUpdated(df, epochId, conn)\n",
    "          \n",
    "   finally:\n",
    "         \n",
    "          if conn==True:\n",
    "            #print(conn)\n",
    "            ibm_db.close(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(alist, wanted_parts):\n",
    "    length = len(alist)\n",
    "    return [ alist[i*length // wanted_parts: (i+1)*length // wanted_parts] \n",
    "             for i in range(wanted_parts) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def dropDupesBadDF(dfbadlists):\n",
    "    \n",
    "   ##### Prepare Bad Data Frame ######\n",
    "   if len(dfbadlists) > 0:\n",
    "       if len(dfbadlists[0]) > 0:\n",
    "          dfb = dfbadlists[0][0]\n",
    "   ctr=0\n",
    "   for dfbadlist in dfbadlists:\n",
    "   \n",
    "     \n",
    "     if len(dfbadlist) > 0:\n",
    "         \n",
    "       if ctr==0:\n",
    "        #dfb=dfb.select(\"ORDER_ID\",\"COLUMN_NAME\",\"COLUMN_VALUE\",\"MSG_PARTITION\",\"MSG_OFFSET\",\"MSG_VALUE\")\n",
    "        for dfbd in dfbadlist[1:]:\n",
    "           #dfbd = dfbd.select(\"ORDER_ID\",\"COLUMN_NAME\",\"COLUMN_VALUE\",\"MSG_PARTITION\",\"MSG_OFFSET\",\"MSG_VALUE\")\n",
    "              #dfb.show()\n",
    "              print(\"^^^^\")\n",
    "              #dfbd.show()\n",
    "              dfb=dfb.union(dfbd)\n",
    "           \n",
    "       else:\n",
    "           \n",
    "           for dfbd in dfbadlist:\n",
    "           #dfbd = dfbd.select(\"ORDER_ID\",\"COLUMN_NAME\",\"COLUMN_VALUE\",\"MSG_PARTITION\",\"MSG_OFFSET\",\"MSG_VALUE\")\n",
    "               #dfb.show()\n",
    "               print(\"%%%%\")\n",
    "               #dfbd.show()\n",
    "               dfb=dfb.union(dfbd)\n",
    "       ctr=ctr+1\n",
    "   if len(dfbadlists) > 0:\n",
    "       if len(dfbadlists[0]) > 0: \n",
    "           dfb=dfb.dropDuplicates()\n",
    "           print(\"**************\")\n",
    "           dfb.show()\n",
    "           print(\"**************\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepareData(dfblk,json_exploded_path_lists,colslist,col_len_lists,epochId,tbllist):\n",
    "    \n",
    "  \n",
    "  qlist=[]  \n",
    "  fullrowslist=[]\n",
    "    \n",
    "  dictlist=[]\n",
    "  colslistup=[]\n",
    "  badorders=[]\n",
    "  badcolumns=[]\n",
    "  column_names_list=[]\n",
    "  column_names_str_list=[]\n",
    "  \n",
    "  print(\"Starting to Detect Bad Orders:........\")\n",
    "  print(datetime.now())  \n",
    "\n",
    "\n",
    "  bad_order_qry_str = \" INSERT INTO KAFKARADIAL.INSERT_FAILED_MSG ( ORDER_ID,COLUMN_NAME, COLUMN_VALUE, MSG_PARTITION, MSG_OFFSET, MSG_VALUE ) VALUES \"\n",
    "  badordervalues=[]\n",
    "  bctr=0\n",
    "  badqlist=[]\n",
    "\n",
    "  for json_exploded_path_list,romlistfinal1,rom_col_len_list, tbl in zip(json_exploded_path_lists,colslist,col_len_lists,tbllist):\n",
    "    \n",
    "       \n",
    "    finaldf,dfbadlist,col_len_list=prepareDFXA(dfblk,json_exploded_path_list,romlistfinal1,rom_col_len_list,epochId,tbl) \n",
    "\n",
    "    print(\"Starting to Collect Dataframe:........\")\n",
    "    print(datetime.now()) \n",
    "\n",
    "    finaldf.persist()\n",
    "    print(\"Completed caching...\")\n",
    "    print(datetime.now()) \n",
    "    column_names = finaldf.columns\n",
    "    column_names_str=','.join(column_names)\n",
    "    column_names_list.append(column_names)\n",
    "    print(\"Completed retrieving Columns...\")\n",
    "    print(datetime.now()) \n",
    "    #tbl_pkeys=pk_dict.get(tbl)\n",
    "    #finaldf.dropDuplicates(tbl_pkeys)\n",
    "    print(\"Completed Dropping Duplicates...\")\n",
    "    print(datetime.now()) \n",
    "    fullrows = finaldf.collect()  \n",
    "    print(\"Completed collecting dataframe...\")\n",
    "    print(datetime.now()) \n",
    "    finaldf.unpersist()\n",
    "    print(\"Completed unpersisting...\")\n",
    "    print(datetime.now()) \n",
    "    \n",
    "    print(\"Ending to Format Data :........\")\n",
    "    print(datetime.now())\n",
    "    \n",
    "    \n",
    "    print(\"Deduplication Begin:........\")\n",
    "    print(datetime.now())\n",
    "    fullrows = list(set(fullrows))\n",
    "    print(\"Deduplication End:........\")\n",
    "    print(datetime.now())\n",
    "    \n",
    "    fullrowslist.append(fullrows)\n",
    "    \n",
    "    \n",
    "    print(\"Starting to prepare rows...\")\n",
    "    print(datetime.now())\n",
    "    \n",
    "    print(\"$$$$$$$$$$$$$$$$$$$$\")\n",
    "    print(tbl)\n",
    "    print(len(fullrows))\n",
    "    print(finaldf.count())\n",
    "    print(\"$$$$$$$$$$$$$$$$$$$$\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    for row in fullrows:\n",
    "            \n",
    "            \n",
    "          if row:\n",
    "            badordinslist=[]\n",
    "            orderid=row[\"ORDER_ID\"]\n",
    "            #msgvalue=row[\"MSG_VALUE\"]\n",
    "            #msgpartition=row[\"MSG_PARTITION\"]\n",
    "            #msgoffset=row[\"MSG_OFFSET\"]\n",
    "            if orderid == '':\n",
    "                badorders.append(orderid)\n",
    "                badordinslist.append(\"?\")\n",
    "                badordinslist.append(\"?\")\n",
    "                badordinslist.append(\"?\")\n",
    "                #badordinslist.append(\"?\")\n",
    "                #badordinslist.append(\"?\")\n",
    "                #badordinslist.append(\"?\")\n",
    "                badordervalues.append(orderid)\n",
    "                badordervalues.append('')\n",
    "                badordervalues.append('')\n",
    "                #badordervalues.append(msgpartition)\n",
    "                #badordervalues.append(msgoffset)\n",
    "                #badordervalues.append(msgvalue)\n",
    "                \n",
    "            #msgvalue=row[\"VALUE\"]\n",
    "            for column,collen in zip(column_names,col_len_list):\n",
    "                colval=row[column]\n",
    "                #print(collen, colval)\n",
    "                if( (collen.strip() != 'INTEGER') and (collen != 'NUMERIC (15,2)') and (collen != 'NUMERIC (14,4)') ):\n",
    "                  if len(str(colval)) > int(collen):\n",
    "                    badorders.append(orderid)\n",
    "                    badordinslist.append(\"?\")\n",
    "                    badordinslist.append(\"?\")\n",
    "                    badordinslist.append(\"?\")\n",
    "                    #badordinslist.append(\"?\")\n",
    "                    #badordinslist.append(\"?\")\n",
    "                    #badordinslist.append(\"?\")\n",
    "                    badordervalues.append(orderid)\n",
    "                    badordervalues.append(column)\n",
    "                    badordervalues.append(str(colval))\n",
    "                    #badordervalues.append(msgpartition)\n",
    "                    #badordervalues.append(msgoffset)\n",
    "                    #badordervalues.append(msgvalue)\n",
    "                    \n",
    "                elif (collen == 'NUMERIC(15,2)' ):\n",
    "                    if len(str(colval)) > 17:\n",
    "                        badorders.append(orderid)\n",
    "                        badordinslist.append(\"?\")\n",
    "                        badordinslist.append(\"?\")\n",
    "                        badordinslist.append(\"?\")\n",
    "                        #badordinslist.append(\"?\")\n",
    "                        #badordinslist.append(\"?\")\n",
    "                        #badordinslist.append(\"?\")\n",
    "                        badordervalues.append(orderid)\n",
    "                        badordervalues.append(column)\n",
    "                        badordervalues.append(str(colval))\n",
    "                        #badordervalues.append(msgpartition)\n",
    "                        #badordervalues.append(msgoffset)\n",
    "                        #badordervalues.append(msgvalue)\n",
    "                        \n",
    "                elif (collen == 'NUMERIC(14,4)') :\n",
    "                    if len(str(colval)) > 18:\n",
    "                        badorders.append(orderid)\n",
    "                        badordinslist.append(\"?\")\n",
    "                        badordinslist.append(\"?\")\n",
    "                        badordinslist.append(\"?\")\n",
    "                        #badordinslist.append(\"?\")\n",
    "                        #badordinslist.append(\"?\")\n",
    "                        #badordinslist.append(\"?\")\n",
    "                        badordervalues.append(orderid)\n",
    "                        badordervalues.append(column)\n",
    "                        badordervalues.append(str(colval))\n",
    "                        #badordervalues.append(msgpartition)\n",
    "                        #badordervalues.append(msgoffset)\n",
    "                       # badordervalues.append(msgvalue)\n",
    "            \n",
    "            if len(badordinslist) > 0:\n",
    "            \n",
    "                strbad = ','.join(badordinslist)\n",
    "                strbad='('+strbad+')'\n",
    "            \n",
    "            \n",
    "            \n",
    "                if bctr==0:\n",
    "              \n",
    "                    bad_order_qry_str=bad_order_qry_str+strbad\n",
    "                    bctr=bctr+1\n",
    "                else:\n",
    "                    bad_order_qry_str=bad_order_qry_str+\" UNION ALL \\n VALUES \"+strbad\n",
    "              \n",
    "  print(\"&&&&&&&&&&&&\")\n",
    "  print(len(badorders))\n",
    "    \n",
    "  if len(badorders) > 0:  \n",
    "        print(\"Entering&&&&&&&&&\")                \n",
    "        badparamtup=tuple(badordervalues)\n",
    "        badqlist.append([bad_order_qry_str,badparamtup])  \n",
    "        print(bad_order_qry_str)\n",
    "        #print(len(badordervalues))\n",
    "        #print(len(badparamtup))\n",
    "        \n",
    "        conn2=connectToDB()      \n",
    "        insertData(badqlist,conn2)\n",
    "        ibm_db.close(conn2)\n",
    "        \n",
    "        \n",
    "        \n",
    "                    \n",
    "  print(\"Bad Orders:********************\")  \n",
    "  badorders=list(set(badorders))\n",
    "  print(len(badorders))\n",
    "  print(badorders)\n",
    "  \n",
    "  print(\"Finished Detecting Bad Orders:........\")\n",
    "  print(datetime.now()) \n",
    "    \n",
    "  print(\"Starting Actual Data Preparation :........\")\n",
    "  print(datetime.now()) \n",
    "    \n",
    "  for fullrows,column_names,romlistfinal1,rom_col_len_list,tbl in zip(fullrowslist,column_names_list,colslist,col_len_lists,tbllist):\n",
    "    \n",
    "    colslistup.append(column_names)\n",
    "    column_names_str=','.join(column_names)\n",
    "    \n",
    "    qry_str=\"INSERT INTO \"+tbl+\" (\"+column_names_str+\") VALUES \"\n",
    "    listval=[]\n",
    "       \n",
    "    \n",
    "    lenarr = len(fullrows)\n",
    "    lenmid = lenarr//2\n",
    "    \n",
    "    rowsfirst = fullrows[:lenmid]\n",
    "    rowssecond = fullrows[lenmid:]\n",
    "    \n",
    "    splitrowslist=[]\n",
    "    splitrowslist.append(rowsfirst)\n",
    "    splitrowslist.append(rowssecond) \n",
    "    \n",
    "  \n",
    "        \n",
    "    splitrowslist=split_list(fullrows,  200)\n",
    "    splitrowslist = [x for x in splitrowslist if x != []]\n",
    "    \n",
    "    # if tbl == 'KAFKARADIAL.ROM_ORDER_LINE_STG0':\n",
    "    #      splitrowslist=split_list(fullrows,  50)\n",
    "    #      splitrowslist = [x for x in splitrowslist if x != []]\n",
    "    \n",
    "    print(\"TBL:**********************************\")\n",
    "    print(tbl)\n",
    "    print(len(splitrowslist))\n",
    "    \n",
    "    \n",
    "    for splitrows in splitrowslist:\n",
    "        \n",
    "        \n",
    "        paramlist=[]\n",
    "        qry_str=\"INSERT INTO \"+tbl+\" (\"+column_names_str+\") VALUES \"\n",
    "        ctr=0\n",
    "        \n",
    "        \n",
    "        for row in splitrows:\n",
    "          #print(row) \n",
    "            \n",
    "          if row:\n",
    "            \n",
    "            \n",
    "           ordid=row[\"ORDER_ID\"]\n",
    "           if ordid not in badorders:\n",
    "            list2=[]\n",
    "            paramlist2=[]\n",
    "            \n",
    "            for column in column_names:\n",
    "                colval=row[column]\n",
    "                if colval == False:\n",
    "                    colval=\"0\"\n",
    "                elif colval == True:\n",
    "                    colval=\"1\"\n",
    "                paramlist.append(colval)\n",
    "                list2.append(\"?\")\n",
    "                paramlist2.append(colval)\n",
    "                \n",
    "            str1 = ','.join(list2)\n",
    "            str1='('+str1+')'\n",
    "            \n",
    "            #listval.append(str1)\n",
    "            #listvalstr=','.join(listval)\n",
    "            if ctr==0:\n",
    "              \n",
    "              qry_str=qry_str+str1\n",
    "              ctr=ctr+1\n",
    "            else:\n",
    "              qry_str=qry_str+\" UNION ALL \\n VALUES \"+str1\n",
    "            #paramlist.append(tuple(list1))\n",
    "        paramtup=tuple(paramlist)\n",
    "        qlist.append([qry_str,paramtup])\n",
    "            \n",
    "        \n",
    "  return qlist\n",
    "\n",
    "  print(\"Ending Actual Data Preparation :........\")\n",
    "  print(datetime.now()) \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def insertFailedBatch(df,epochId):\n",
    "    \n",
    "    tbl=\"KAFKARADIAL.INSERT_FAILED_BATCH\"\n",
    "    \n",
    "    fdf=df.select(\"order.id\",\"partition\",\"offset\",\"value\")\n",
    "    fdf=fdf.withColumnRenamed(\"id\", \"ORDER_ID\")\n",
    "    fdf=fdf.withColumnRenamed(\"partition\", \"MSG_PARTITION\") \n",
    "    fdf=fdf.withColumnRenamed(\"offset\", \"MSG_OFFSET\") \n",
    "    fdf=fdf.withColumnRenamed(\"value\", \"MSG_VALUE\") \n",
    "    \n",
    "    writeToSQLWarehouse(fdf, epochId, tbl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def insertBatch(df,epochId):\n",
    "    \n",
    "    tbl=\"KAFKARADIAL.INSERT_BATCH\"\n",
    "    \n",
    "    fdf=df.select(\"order.id\",\"partition\",\"offset\",\"value\")\n",
    "    fdf=fdf.withColumnRenamed(\"id\", \"ORDER_ID\")\n",
    "    fdf=fdf.withColumnRenamed(\"partition\", \"MSG_PARTITION\") \n",
    "    fdf=fdf.withColumnRenamed(\"offset\", \"MSG_OFFSET\") \n",
    "    fdf=fdf.withColumnRenamed(\"value\", \"MSG_VALUE\") \n",
    "    \n",
    "    writeToSQLWarehouse(fdf, epochId, tbl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertData(qlist,conn):\n",
    "    \n",
    "    \n",
    "    for q in qlist:\n",
    "        qry=q[0]\n",
    "        param=q[1]\n",
    "        stmt = ibm_db.prepare(conn, qry)\n",
    "        print(\"here***\")\n",
    "        print(qry.splitlines()[0])\n",
    "        #print(type(param))\n",
    "        #print(param)\n",
    "        print(datetime.now()) \n",
    "        ibm_db.execute(stmt, param)\n",
    "        print(datetime.now()) \n",
    "        print(\"here####\")\n",
    "    ibm_db.commit(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def insSingleData(dictlist,tbllist,colslist,conn):\n",
    "    \n",
    "  print(datetime.datetime.now())\n",
    "  #finaldford=finaldflist[0].groupBy(\"ORDER_ID\").count()\n",
    "  finaldfordlist=dictlist[0].keys()\n",
    "  print(len(finaldfordlist))\n",
    "        \n",
    "  qry=\"\"\n",
    "  param=\"\"\n",
    "    \n",
    "    \n",
    "  for orderidrow in finaldfordlist:   \n",
    "    \n",
    "        \n",
    "    try:\n",
    "        \n",
    "        \n",
    "      qlist=[]   \n",
    "    \n",
    "      for dictelm,cols,tbl in zip(dictlist,colslist,tbllist):\n",
    "        \n",
    "        \n",
    "          column_names_str=','.join(cols)\n",
    "        \n",
    "          paramlist=[]\n",
    "          qry_str=\"INSERT INTO \"+tbl+\" (\"+column_names_str+\") VALUES \"\n",
    "          ctr=0\n",
    "    \n",
    "        \n",
    "          rowsordlistnew = dictelm[orderidrow]\n",
    "          #print(len(rowsordlistnew))\n",
    "          \n",
    "          for row in rowsordlistnew:\n",
    "            \n",
    "            #print(row)\n",
    "            \n",
    "            list2=[]\n",
    "            str1=row[0]\n",
    "            parampartlist=row[1]\n",
    "            paramlist=paramlist+parampartlist\n",
    "            \n",
    "            if ctr==0:\n",
    "                \n",
    "              qry_str=qry_str+str1\n",
    "              ctr=ctr+1\n",
    "                \n",
    "            else:\n",
    "                \n",
    "              qry_str=qry_str+\" UNION ALL \\n VALUES \"+str1\n",
    "            \n",
    "            #paramlist.append(tuple(list1))\n",
    "            \n",
    "          paramtup=tuple(paramlist)\n",
    "          qlist.append([qry_str,paramtup])\n",
    "            \n",
    "    \n",
    "      insertSingleData(qlist,conn)    \n",
    "        \n",
    "    except Exception as e:\n",
    "            \n",
    "             print(\"hereÃ«ee....\")\n",
    "             exp_tb=traceback.format_exc()\n",
    "             print(exp_tb)\n",
    "             ibm_db.rollback(conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explodeDFJSON(df):\n",
    "  \n",
    "      #df=df.withColumn(\"order\", df.value.order)\n",
    "      #df=df.withColumn(\"customAttributes\", df.value.customAttributes)\n",
    "      #df=df.withColumn(\"topicName\", df.value.topicName)\n",
    "      #df=df.drop(\"value\")\n",
    "      #df.show()\n",
    "    \n",
    "      \n",
    "      for i, row in arraysdf.iterrows():\n",
    "      \n",
    "          json_path_to_explode=row['JSON_PATH_TO_EXPLODE']\n",
    "          json_path_exploded=row['JSON_PATH_EXPLODED']\n",
    "          print(json_path_to_explode)\n",
    "          print(json_path_exploded)\n",
    "      \n",
    "          df=df.withColumn(json_path_exploded,explode_outer(json_path_to_explode))\n",
    "          df.show()\n",
    "          \n",
    "      return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateDF(sdf,tbl):\n",
    "    \n",
    "    #sdf.printSchema()\n",
    "    if tbl==\"KAFKARADIAL.ROM_ORDER_LINE_STG0\":\n",
    "       try:\n",
    "        sdf=sdf.withColumn(\"IS_ASSOCIATE_DELIVERY\", when(col(\"IS_ASSOCIATE_DELIVERY\") == \"false\",lit(\"0\") )        .when(col(\"IS_ASSOCIATE_DELIVERY\") == \"true\",lit(\"1\"))         .otherwise(col(\"IS_ASSOCIATE_DELIVERY\")))\n",
    "       except Exception as e:\n",
    "         print(e)\n",
    "    \n",
    "    return sdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pk_dict = {'ROM_ORDER_HEADER_STG0': ['ORDER_ID'],\n",
    "           \n",
    "           'ROM_ORDER_LINE_STG0': ['ORDER_ID', 'ORDER_LINE_ID'],\n",
    "           \n",
    "           'ROM_RELATED_ORDERS_STG0' : ['ORDER_ID', 'RELATED_ORDER_ID'],\n",
    "           \n",
    "           'ROM_ORDER_PAYMENT_STG0' : ['ORDER_ID', 'TENDER_TYPE', 'PAYMENT_ACCT_NO'],\n",
    "           \n",
    "           'ROM_ORDER_PROMOTION_STG0' : ['ORDER_ID', 'ORDER_LINE_ID', 'ORDER_DISCOUNT_ID'],\n",
    "           \n",
    "           'ROM_ORDER_REFERENCES_STG0' : ['ORDER_ID', 'REFERENCE_TYPE', 'ATTRIB_NAME', 'ATTRIB_VALUE'],\n",
    "           \n",
    "           'ROM_ORDER_TAX_BREAKUP_STG0' : ['ORDER_ID', 'ORDER_LINE_ID', 'ORDER_SUB_LINE_ID', \n",
    "                                           'ORDER_CHARGE_ID', 'ORDER_DISCOUNT_ID'],\n",
    "           \n",
    "           'ROM_ORDER_LINE_RELATIONSHIP_STG0' : ['ORDER_ID', 'RELATION_TYPE', \n",
    "                                                'PARENT_LINE_ID', 'CHILD_LINE_ID'],\n",
    "           \n",
    "           'ROM_ORDER_CUSTOMER_INFO_STG0' : ['ORDER_ID', 'CUSTOMER_INFO_ID'],\n",
    "           \n",
    "           'ROM_ORDER_LINE_CHARGES_STG0' : ['ORDER_ID', 'ORDER_LINE_ID', 'ORDER_SUB_LINE_ID', \n",
    "                                            'ORDER_CHARGE_ID', 'ORDER_DISCOUNT_ID'],\n",
    "           \n",
    "           'ROM_ORDER_LINE_STATUS_STG0' : ['ORDER_ID', 'ORDER_LINE_ID', 'ORDER_SUB_LINE_ID',\n",
    "                                           'STATUS_QTY', 'STATUS_ID']\n",
    "    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v=pk_dict.get('ROM_ORDER_HEADER_STG0')\n",
    "type(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsondf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def updateDFSplFields_ROM_ORDER_HEADER_STG0(df, jsonpathlist_clean, rom_list_clean, romlen_list_clean):\n",
    "    \n",
    "    \n",
    "        try:\n",
    "        \n",
    "            df = df.withColumn(\"ORDER_HEADER_KEY\", concat(col(\"order.sellerId\"), lit(\"-\"), col(\"order.id\")))\n",
    "            jsonpathlist_clean.append(\"ORDER_HEADER_KEY\")\n",
    "            rom_list_clean.append(\"ORDER_HEADER_KEY\")\n",
    "            romlen_list_clean.append(\"1000000\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "             print(\" Can't obtain ORDER_HEADER_KEY \")\n",
    "             print(e)\n",
    "        \n",
    "        \n",
    "        try: \n",
    "    \n",
    "           df.select(\"order.hfrNumber\")\n",
    "           #df=df.withColumn(\"HFR_NUMBER\" , col(\"order.hfrNumber\") )\n",
    "           jsonpathlist_clean.append(\"order.hfrNumber\")\n",
    "           rom_list_clean.append(\"HFR_NUMBER\")\n",
    "           romlen_list_clean.append(\"100000\") \n",
    "\n",
    "        except Exception as e:\n",
    "    \n",
    "            try:\n",
    "        \n",
    "                df.select(\"order.raNumber\")\n",
    "                #df=df.withColumn(\"HFR_NUMBER\" , col(\"order.raNumber\") )\n",
    "                jsonpathlist_clean.append(\"order.raNumber\")\n",
    "                rom_list_clean.append(\"HFR_NUMBER\")\n",
    "                romlen_list_clean.append(\"100000\")\n",
    "        \n",
    "            except Exception as e:\n",
    "        \n",
    "                print(\" HFR NUMBER order.hfrNumber or order.raNumber NOT PRESENT \")\n",
    "            \n",
    "            \n",
    "        try: \n",
    "    \n",
    "           df.select(\"order.billingAddressRefId\")\n",
    "           #df=df.withColumn(\"BILL_TO_KEY\" , col(\"order.billingAddressRefId\") )\n",
    "           jsonpathlist_clean.append(\"order.billingAddressRefId\")\n",
    "           rom_list_clean.append(\"BILL_TO_KEY\")\n",
    "           romlen_list_clean.append(\"100000\") \n",
    "\n",
    "        except Exception as e:\n",
    "        \n",
    "            print(\" BILL_TO_KEY -->  order.billingAddressRefId NOT PRESENT \")\n",
    "            \n",
    "            \n",
    "        return df, jsonpathlist_clean, rom_list_clean,romlen_list_clean\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def updateDFSplFields_ROM_ORDER_LINE_STG0(df, jsonpathlist_clean,rom_list_clean,romlen_list_clean ):\n",
    "    \n",
    "        try: \n",
    "            \n",
    "           df2 = df.groupBy(col(\"order.id\"), col(\"order_lineItems_sublineItems.quantity\")).sum(\"order_lineItems_sublineItems.quantity\")\n",
    "           df2 = df2.withColumnRenamed(\"sum(order_lineItems_sublineItems.quantity AS `quantity`)\", \"ORDERED_QTY\") \n",
    "           \n",
    "           df=df.alias('a').join(df2.alias('b'),col('b.id') == col('a.order.id')).select(\"a.*\",\"b.ORDERED_QTY\")\n",
    "\n",
    "            \n",
    "           jsonpathlist_clean.append(\"ORDERED_QTY\")\n",
    "           rom_list_clean.append(\"ORDERED_QTY\")\n",
    "           romlen_list_clean.append(\"100000\") \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            try:\n",
    "                \n",
    "                df = df.groupBy(col(\"order.id\"), col(\"order_lineItems.quantity\")).sum(\"order_lineItems.quantity\")\n",
    "                df = df.withColumnRenamed(\"sum(order_lineItems.quantity AS `quantity`)\", \"ORDERED_QTY\") \n",
    "                jsonpathlist_clean.append(\"ORDERED_QTY\")\n",
    "                rom_list_clean.append(\"ORDERED_QTY\")\n",
    "                romlen_list_clean.append(\"10000\")\n",
    "                \n",
    "            except Exception as e:    \n",
    "                print(e)\n",
    "                print(\" ORDERED_QTY not present \")\n",
    "                \n",
    "                 \n",
    "        try: \n",
    "           print(\"********\")\n",
    "           #df.show()\n",
    "           df.select(\"order_lineItems.shippingAddressRefId\")\n",
    "           #df=df.withColumn(\"SHIP_TO_KEY\" , col(\"order_lineItems.shippingAddressRefId\") )\n",
    "           jsonpathlist_clean.append(\"order_lineItems.shippingAddressRefId\")\n",
    "           rom_list_clean.append(\"SHIP_TO_KEY\")\n",
    "           romlen_list_clean.append(\"100000\") \n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\" SHIP_TO_KEY -->  order_lineItems.shippingAddressRefId NOT PRESENT \")\n",
    "            \n",
    "    \n",
    "        return df, jsonpathlist_clean,rom_list_clean,romlen_list_clean\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def updateDFSplFields_ROM_RELATED_ORDERS_STG0( df,jsonpathlist_clean,rom_list_clean,romlen_list_clean ):\n",
    "\n",
    "    try: \n",
    "            df.select(\"order.id\",\"order.sellerId\",\"order_relatedOrders.id\",\"order_relatedOrders_relatedLines.lineNo\",\"order_relatedOrders_relatedLines.originalLineNo\" )\n",
    "            df = df.withColumn(\"RELATED_ORDER_KEY\", concat(col(\"order.id\"), lit(\"-\"), col(\"order.sellerId\"), \n",
    "                 lit(\"-\"),  col(\"order_relatedOrders.id\"),  lit(\"-\"), col(\"order_relatedOrders_relatedLines.lineNo\"),\n",
    "                 lit(\"-\"),  col(\"order_relatedOrders_relatedLines.originalLineNo\")    ))\n",
    "            \n",
    "            jsonpathlist_clean.append(\"RELATED_ORDER_KEY\")\n",
    "            rom_list_clean.append(\"RELATED_ORDER_KEY\")\n",
    "            romlen_list_clean.append(\"100000\")\n",
    "            \n",
    "    except Exception as e:    \n",
    "                jsonpathlist_clean=[]\n",
    "                rom_list_clean=[] \n",
    "                romlen_list_clean=[]\n",
    "                print(\" RELATED_ORDER_KEY not present \")\n",
    "                \n",
    "                \n",
    "    return df,jsonpathlist_clean,rom_list_clean,romlen_list_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateDFSplFields_ROM_ORDER_PAYMENT_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n",
    "\n",
    "\n",
    "         try:\n",
    "            \n",
    "            \n",
    "            df.select(\"order_paymentMethods.code\",\"order_paymentMethods.creditCardNumber\")     \n",
    "            df=df.withColumn(\"PAYMENT_ACCT_NO\", when(col(\"order_paymentMethods.code\") == \"CREDIT_CARD\",col(\"order_paymentMethods.creditCardNumber\") )      \n",
    "                     .otherwise(None))\n",
    "            \n",
    "         except Exception as e:\n",
    "            \n",
    "            print(e)\n",
    "\n",
    "         try:\n",
    "            \n",
    "            \n",
    "            df.select(\"order_paymentMethods.code\",\"order_paymentMethods.payPalNumber\")     \n",
    "            df=df.withColumn(\"PAYMENT_ACCT_NO\", when(col(\"order_paymentMethods.code\") == \"PAYPAL\",col(\"order_paymentMethods.payPalNumber\") )      \n",
    "                     .otherwise(None))\n",
    "            \n",
    "         except Exception as e:\n",
    "            \n",
    "            print(e)\n",
    "            \n",
    "            \n",
    "         try:\n",
    "            \n",
    "            \n",
    "            df.select(\"order_paymentMethods.code\",\"order_paymentMethods.storedValueCardNumber\")     \n",
    "            df=df.withColumn(\"PAYMENT_ACCT_NO\", when(col(\"order_paymentMethods.code\") == \"STORED_VALUE_CARD\",col(\"order_paymentMethods.storedValueCardNumber\") )      \n",
    "                     .otherwise(None))\n",
    "            \n",
    "         except Exception as e:\n",
    "            \n",
    "            print(e)\n",
    "            \n",
    "            \n",
    "         try:\n",
    "            \n",
    "            \n",
    "            df.select(\"order_paymentMethods.code\",\"order_paymentMethods.storedValueCardNumber\")     \n",
    "            df=df.withColumn(\"PAYMENT_ACCT_NO\", when(col(\"order_paymentMethods.code\") == \"PREPAID_CARD\",None))\n",
    "            \n",
    "         except Exception as e:\n",
    "            \n",
    "            print(e)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #try:\n",
    "            \n",
    "            \n",
    "            #df = df.withColumn(\"PAYMENT_ACCT_NO\", when(col(\"order_paymentMethods.code\") == \"CREDIT_CARD\",col(\"order_paymentMethods.creditCardNumber\") )      \n",
    "                     #.when(col(\"order_paymentMethods.code\") == \"PAYPAL\",col(\"order_paymentMethods.payPalNumber\")) \n",
    "                     #.when(col(\"order_paymentMethods.code\") == \"STORED_VALUE_CARD\",col(\"order_paymentMethods.storedValueCardNumber\"))\n",
    "                     #.when(col(\"order_paymentMethods.code\") == \"PREPAID_CARD\",None )\n",
    "                     #.otherwise(None))\n",
    "            \n",
    "        #except Exception as e:\n",
    "            \n",
    "            #print(\"PAYMENT_ACCT_NO not found\")\n",
    "\n",
    "\n",
    "         try:\n",
    "        \n",
    "           ## OrderId + tenderType + AccountNo  ## AccountNo - verify Mapping \n",
    "           df = df.withColumn(\"PAYMENT_KEY\", concat_ws('',col(\"order.id\"), lit(\"-\"), col(\"order_paymentMethods.tenderType\"), \n",
    "                            lit(\"-\"),  col(\"PAYMENT_ACCT_NO\")))\n",
    "                            \n",
    "           jsonpathlist_clean.append(\"PAYMENT_KEY\")\n",
    "           rom_list_clean.append(\"PAYMENT_KEY\")\n",
    "           romlen_list_clean.append(\"100000\")  \n",
    "           \n",
    "           #df.select(\"order_paymentMethods.code\",\"PAYMENT_KEY\").show() \n",
    "         except Exception as e:\n",
    "              \n",
    "            print(\"PAYMENT_KEY not found\")\n",
    "            print(e)   \n",
    "                                                    \n",
    "                                                    \n",
    "                                                    \n",
    "         return df, jsonpathlist_clean,rom_list_clean,romlen_list_clean\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateDFSplFields_ROM_ORDER_PROMOTION_STG0( df,jsonpathlist_clean,rom_list_clean,romlen_list_clean ):\n",
    "\n",
    "\n",
    "       try:   \n",
    "            \n",
    "           df.select(\"order.id\",\"order_lineItems.lineNo\",\"order_lineItems_sublineItems.sublineNo\",\"order_lineItems_charges.id\",\"order_lineItems_charges_discounts.id\")                                          \n",
    "           ### OrderId + LineNo + SubLineNo + ChargeId + DiscountsId\n",
    "           df = df.withColumn(\"PROMOTION_KEY\", concat(col(\"order.id\"), lit(\"-\"), col(\"order_lineItems.lineNo\"), \n",
    "                 lit(\"-\"),  col(\"order_lineItems_sublineItems.sublineNo\"),  lit(\"-\"), col(\"order_lineItems_charges.id\"),\n",
    "                 lit(\"-\"),  col(\"order_lineItems_charges_discounts.id\")    ))  \n",
    "                                                    \n",
    "           jsonpathlist_clean.append(\"PROMOTION_KEY\")\n",
    "           rom_list_clean.append(\"PROMOTION_KEY\")    \n",
    "           romlen_list_clean.append(\"100000\") \n",
    "                                                    \n",
    "       except Exception as e:\n",
    "            jsonpathlist_clean=[]\n",
    "            rom_list_clean=[] \n",
    "            print(e) \n",
    "            print(\"PROMOTION_KEY not found\")\n",
    "            \n",
    "                                   \n",
    "       #print(jsonpathlist_clean)  \n",
    "    \n",
    "                                                    \n",
    "       if \"PROMOTION_KEY\" in jsonpathlist_clean: \n",
    "\n",
    "        \n",
    "        try: \n",
    "            \n",
    "           df.select(\"*\",\"order_lineItems_charges_discounts_customAttributes.name\",\"order_lineItems_charges_discounts_customAttributes.value\") \n",
    "           df=df.select(\"*\",\"order_lineItems_charges_discounts_customAttributes.name\",col(\"order_lineItems_charges_discounts_customAttributes.value\").alias(\"cvalue\"))\n",
    "           df=df.withColumnRenamed(\"name\", \"PROMO_CUSTOM_NAME\")\n",
    "           df=df.withColumnRenamed(\"cvalue\", \"PROMO_CUSTOM_VALUE\")\n",
    "           df.show()\n",
    "                                                    \n",
    "           try:\n",
    "            \n",
    "                df = df.withColumn(  \"PROMOTION_ID\", \n",
    "                         when( col(\"PROMO_CUSTOM_NAME\") == \"promoold\", col(\"PROMO_CUSTOM_VALUE\") )\n",
    "                       .otherwise(None) )\n",
    "                jsonpathlist_clean.append(\"PROMOTION_ID\")\n",
    "                rom_list_clean.append(\"PROMOTION_ID\")    \n",
    "                romlen_list_clean.append(\"100000\") \n",
    "            \n",
    "           except Exception as e:\n",
    "               \n",
    "               print(\"PROMOTION_ID not retrieved\")\n",
    "               #print(e)\n",
    "                                                    \n",
    "           try:\n",
    "            \n",
    "            \n",
    "                df = df.withColumn(  \"PROMOTION_DESCRIPTION\", \n",
    "                         when( col(\"PROMO_CUSTOM_NAME\") == \"promoDescription\", col(\"PROMO_CUSTOM_VALUE\") ) \n",
    "                        .otherwise(None) )\n",
    "                jsonpathlist_clean.append(\"PROMOTION_DESCRIPTION\")\n",
    "                rom_list_clean.append(\"PROMOTION_DESCRIPTION\")    \n",
    "                romlen_list_clean.append(\"100000\") \n",
    "            \n",
    "           except Exception as e:\n",
    "               \n",
    "               print(\"PROMOTION_DESCRIPTION not retrieved\")\n",
    "               #print(e)\n",
    "                                                    \n",
    "                                                    \n",
    "           try:\n",
    "            \n",
    "            \n",
    "                df = df.withColumn(  \"PROMOTION_CODE\", \n",
    "                         when( col(\"PROMO_CUSTOM_NAME\") == \"promoCode\", col(\"PROMO_CUSTOM_VALUE\") ) \n",
    "                        .otherwise(None) )\n",
    "                jsonpathlist_clean.append(\"PROMOTION_CODE\")\n",
    "                rom_list_clean.append(\"PROMOTION_CODE\")    \n",
    "                romlen_list_clean.append(\"100000\") \n",
    "            \n",
    "           except Exception as e:\n",
    "               \n",
    "               print(\"PROMOTION_CODE not retrieved\")\n",
    "               #print(e)\n",
    "                            \n",
    "           try:\n",
    "            \n",
    "            \n",
    "                df = df.withColumn(  \"PROMO_EFFECT_TYPE\", \n",
    "                         when( col(\"PROMO_EFFECT_TYPE\") == \"EffectType\", col(\"PROMO_CUSTOM_VALUE\") ) \n",
    "                        .otherwise(None) )\n",
    "                jsonpathlist_clean.append(\"PROMO_EFFECT_TYPE\")\n",
    "                rom_list_clean.append(\"PROMO_EFFECT_TYPE\")    \n",
    "                romlen_list_clean.append(\"100000\") \n",
    "            \n",
    "           except Exception as e:\n",
    "               \n",
    "               print(\"PROMO_EFFECT_TYPE not retrieved\")\n",
    "               #print(e)                                         \n",
    "                                                    \n",
    "        except Exception as e:\n",
    "               \n",
    "               print(\" Can't retrieve Promotion Custom Attributes\")\n",
    "               #print(e)\n",
    "                                                    \n",
    "\n",
    "                    \n",
    "       return df,jsonpathlist_clean,rom_list_clean,romlen_list_clean       \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateDFSplFields_ROM_ORDER_REFERENCES_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n",
    "    \n",
    "    \n",
    "           dft = spark.createDataFrame([], StructType([]))\n",
    "           dft1 = spark.createDataFrame([], StructType([]))\n",
    "           dft2 = spark.createDataFrame([], StructType([]))\n",
    "           dft3 = spark.createDataFrame([], StructType([]))\n",
    "           dft4 = spark.createDataFrame([], StructType([]))\n",
    "            \n",
    "           dfarr=[]\n",
    "    \n",
    "           try:\n",
    "\n",
    "               \n",
    "               dfexp = df.withColumn(\"order_customAttributes\",explode(\"order.customAttributes\"))\n",
    "                \n",
    "               if dfexp.rdd.isEmpty():\n",
    "                \n",
    "                   print(dfexp.rdd.isEmpty)\n",
    "                    \n",
    "               else:\n",
    "                \n",
    "                   dft=df.withColumn(\"REFERENCE_TYPE\", lit(\"ORDER\"))\n",
    "                   dft = dft.withColumn(\"REFERENCE_KEY\", col(\"order.id\"))\n",
    "                   dft = dft.withColumn(\"ATTRIB_NAME\", col(\"order_customAttributes.name\"))\n",
    "                   dft = dft.withColumn(\"ATTRIB_VALUE\", col(\"order_customAttributes.value\"))\n",
    "                   dft = dft.drop(\"order_customAttributes\")\n",
    "                   dfarr.append(dft)\n",
    "                    \n",
    "                   print(\"AT ORDER\")\n",
    "                \n",
    "                \n",
    "                                                    \n",
    "           except Exception as e:\n",
    "                                                    \n",
    "                  print(e)  \n",
    "                              \n",
    "                        \n",
    "           try:\n",
    "            \n",
    "               dfexp = df.withColumn(\"order_charges_customAttributes\",explode(\"order_charges.customAttributes\"))\n",
    "                \n",
    "               if dfexp.rdd.isEmpty():\n",
    "                \n",
    "                   print(dfexp.rdd.isEmpty)\n",
    "                    \n",
    "               else:\n",
    "                \n",
    "                   dft1=dfexp.withColumn(\"REFERENCE_TYPE\", lit(\"CHARGES\"))\n",
    "                   dft1 = dft1.withColumn(\"REFERENCE_KEY\", col(\"order.id\"))\n",
    "                   dft1 = dft1.withColumn(\"ATTRIB_NAME\", col(\"order_charges_customAttributes.name\"))\n",
    "                   dft1 = dft1.withColumn(\"ATTRIB_VALUE\", col(\"order_charges_customAttributes.value\")) \n",
    "                   dft1 = dft1.drop(\"order_charges_customAttributes\")\n",
    "                   dfarr.append(dft1)\n",
    "                    \n",
    "                   print(\"AT CHARGES\")\n",
    "                                                                    \n",
    "           except Exception as e:\n",
    "                  \n",
    "                  print(\"Can't find CHARGES\")\n",
    "                  #print(e)\n",
    "                                                    \n",
    "           try:\n",
    "                                                    \n",
    "               dfexp = df.withColumn(\"order_lineItems_customAttributes\",explode(\"order_lineItems.customAttributes\"))\n",
    "                \n",
    "               if dfexp.rdd.isEmpty():\n",
    "                \n",
    "                   print(dfexp.rdd.isEmpty)\n",
    "                    \n",
    "               else:\n",
    "                \n",
    "                   dft2=dfexp.withColumn(\"REFERENCE_TYPE\", lit(\"LINE\"))\n",
    "                   dft2 = dft2.withColumn(\"REFERENCE_KEY\", col(\"order.id\"))\n",
    "                   dft2 = dft2.withColumn(\"ATTRIB_NAME\", col(\"order_lineItems_customAttributes.name\"))\n",
    "                   dft2 = dft2.withColumn(\"ATTRIB_VALUE\", col(\"order_lineItems_customAttributes.value\")) \n",
    "                   dft2 = dft2.drop(\"order_lineItems_customAttributes\")\n",
    "                   dfarr.append(dft2)\n",
    "                   print(\"********\")\n",
    "                   print(dft2.columns) \n",
    "                   print(\"AT LINE\")\n",
    "                   print(\"********\")\n",
    "                \n",
    "                                                    \n",
    "           except Exception as e:\n",
    "                  \n",
    "                  print(\"Can't find LINE\")\n",
    "                  #print(e)\n",
    "                                                    \n",
    "            \n",
    "           try:\n",
    "            \n",
    "               dfexp = df.withColumn(\"order_lineItems_charges_customAttributes\",explode(\"order_lineItems_charges.customAttributes\"))\n",
    "            \n",
    "               if dfexp.rdd.isEmpty():\n",
    "                \n",
    "                   print(dfexp.rdd.isEmpty)\n",
    "                    \n",
    "               else:\n",
    "                \n",
    "                   dft3=dfexp.withColumn(\"REFERENCE_TYPE\", lit(\"LINE_CHARGES\"))\n",
    "                   dft3 = dft3.withColumn(\"REFERENCE_KEY\", col(\"order.id\"))\n",
    "                   dft3 = dft3.withColumn(\"ATTRIB_NAME\", col(\"order_lineItems_charges_customAttributes.name\"))\n",
    "                   dft3 = dft3.withColumn(\"ATTRIB_VALUE\", col(\"order_lineItems_charges_customAttributes.value\")) \n",
    "                   dft3 = dft3.drop(\"order_lineItems_charges_customAttributes\")\n",
    "                   dfarr.append(dft3)\n",
    "                    \n",
    "                   print(\"AT LINE_CHARGES\") \n",
    "               \n",
    "                                                    \n",
    "           except Exception as e:\n",
    "            \n",
    "                  print(\"Can't find LINE_CHARGES\")\n",
    "                                                    \n",
    "                  #print(e)\n",
    "                                                    \n",
    "            \n",
    "           try:\n",
    "\n",
    "               dfexp = df.withColumn(\"order_paymentMethods_customAttributes\",explode(\"order_paymentMethods.customAttributes\"))\n",
    "            \n",
    "               if dfexp.rdd.isEmpty():\n",
    "                \n",
    "                   print(dfexp.rdd.isEmpty)\n",
    "                    \n",
    "               else:\n",
    "                \n",
    "                   dft4=dfexp.withColumn(\"REFERENCE_TYPE\", lit(\"PAYMENT\"))\n",
    "                   dft4 = dft4.withColumn(\"REFERENCE_KEY\", col(\"order.id\"))\n",
    "                   dft3 = dft3.withColumn(\"ATTRIB_NAME\", col(\"order_paymentMethods_customAttributes.name\"))\n",
    "                   dft3 = dft3.withColumn(\"ATTRIB_VALUE\", col(\"order_paymentMethods_customAttributes.value\")) \n",
    "                   dft4 = dft4.drop(\"order_paymentMethods_customAttributes\")\n",
    "                   dfarr.append(dft4)\n",
    "                    \n",
    "                   print(\"AT PAYMENT\") \n",
    "                    \n",
    "                                                    \n",
    "           except Exception as e:\n",
    "                  \n",
    "                  print(\"Can't find PAYMENT\")\n",
    "                  #print(e)    \n",
    "                    \n",
    "                    \n",
    "           try: \n",
    "            \n",
    "               if dfarr:\n",
    "              \n",
    "                  for dfe in dfarr[1:]:\n",
    "                    \n",
    "                        dfe.select(\"REFERENCE_TYPE\", \"REFERENCE_KEY\").show(2)\n",
    "                        \n",
    "                        print(dft.columns)\n",
    "                        print(\"==========================\")\n",
    "                        print(dfe.columns)\n",
    "                    \n",
    "                        dft = dft.union(dfe)\n",
    "                \n",
    "                  df=dft\n",
    "                    \n",
    "                  jsonpathlist_clean.append(\"REFERENCE_KEY\")\n",
    "                  rom_list_clean.append(\"REFERENCE_KEY\")    \n",
    "                  romlen_list_clean.append(\"100000\")   \n",
    "                \n",
    "                  jsonpathlist_clean.append(\"REFERENCE_TYPE\")\n",
    "                  rom_list_clean.append(\"REFERENCE_TYPE\")    \n",
    "                  romlen_list_clean.append(\"0\")\n",
    "                    \n",
    "           except Exception as e:\n",
    "                  \n",
    "                  print(\"Error during union\")                                  \n",
    "                  print(e)\n",
    "                    \n",
    "                \n",
    "           return df,jsonpathlist_clean,rom_list_clean,romlen_list_clean\n",
    "                                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateDFSplFields_ROM_ORDER_TAX_BREAKUP_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n",
    "    \n",
    "    try:                                            \n",
    "                                                    \n",
    "           ### TAX_BREAKUP_KEY: OrderId + LineNo + SubLineNo + ChargeId + DiscountsId + TaxSequence \n",
    "           ### Need to check on Tax Sequence.   \n",
    "           df.select(\"order.id\",\"order_lineItems.lineNo\",\"order_lineItems_sublineItems.sublineNo\",\"order_lineItems_charges.id\",\"order_lineItems_charges_discounts.id\",\"TaxSequence\")\n",
    "           df = df.withColumn(\"TAX_BREAKUP_KEY\", concat(col(\"order.id\"), lit(\"-\"), col(\"order_lineItems.lineNo\"), \n",
    "                 lit(\"-\"),  col(\"order_lineItems_sublineItems.sublineNo\"),  lit(\"-\"), col(\"order_lineItems_charges.id\"),\n",
    "                 lit(\"-\"),  col(\"order_lineItems_charges_discounts.id\"), lit(\"-\"),col(\"TaxSequence\")    ))  \n",
    "                                                    \n",
    "           jsonpathlist_clean.append(\"TAX_BREAKUP_KEY\")\n",
    "           rom_list_clean.append(\"TAX_BREAKUP_KEY\")  \n",
    "           romlen_list_clean.append(\"100000\") \n",
    "                                                    \n",
    "    except Exception as e:\n",
    "              \n",
    "            print(\"TAX_BREAKUP_KEY not found\")\n",
    "            #print(e)   \n",
    "            \n",
    "            \n",
    "    return df,jsonpathlist_clean,rom_list_clean,romlen_list_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateDFSplFields_ROM_ORDER_LINE_RELATIONSHIP_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n",
    "    \n",
    "    try:                                                 \n",
    "             \n",
    "           ### RELATED_ORDER_KEY: SellerId + OrderId + RelType + ParentLineNo + ChileLineNo\n",
    "           df.select(\"order.sellerId\",\"order.id\",\"order_relatedOrders.type\",\"order_lineItems.lineNo\",\"order_relatedOrders_relatedLines.lineNo\")\n",
    "           df = df.withColumn(\"RELATED_ORDER_KEY\", concat(col(\"order.sellerId\"), lit(\"-\"), col(\"order.id\"), \n",
    "                 lit(\"-\"),  col(\"order_relatedOrders.type\"),  lit(\"-\"), col(\"order_lineItems.lineNo\"),\n",
    "                 lit(\"-\"),  col(\"order_relatedOrders_relatedLines.lineNo\") ))  \n",
    "                                                    \n",
    "           jsonpathlist_clean.append(\"RELATED_ORDER_KEY\")\n",
    "           rom_list_clean.append(\"RELATED_ORDER_KEY\")    \n",
    "           romlen_list_clean.append(\"100000\") \n",
    "                                                    \n",
    "    except Exception as e:\n",
    "            jsonpathlist_clean = []\n",
    "            rom_list_clean = []\n",
    "            romlen_list_clean = []\n",
    "            print(\"RELATED_ORDER_KEY not found\")\n",
    "            #print(e)  \n",
    "            \n",
    "    return df, jsonpathlist_clean,rom_list_clean,romlen_list_clean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateDFSplFields_ROM_ORDER_LINE_CHARGES_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n",
    "    \n",
    "           try:   \n",
    "                                                    \n",
    "            ### LINE_CHARGES_KEY:  OrderId + LineNo + SubLineNo + ChargeId + DiscountsId\n",
    "            df.select(\"order.id\",\"order_lineItems.lineNo\",\"order_lineItems_sublineItems.sublineNo\",\"order_lineItems_charges.id\",\"order_lineItems_charges_discounts.id\")\n",
    "            \n",
    "            df = df.withColumn(\"LINE_CHARGES_KEY\", concat(col(\"order.id\"), lit(\"-\"),  col(\"order_lineItems.lineNo\"),\n",
    "                 lit(\"-\"),  col(\"order_lineItems_sublineItems.sublineNo\"),\n",
    "                 lit(\"-\"),  col(\"order_lineItems_charges.id\"),\n",
    "                 lit(\"-\"),  col(\"order_lineItems_charges_discounts.id\") ))  \n",
    "                                                    \n",
    "            jsonpathlist_clean.append(\"LINE_CHARGES_KEY\")\n",
    "            rom_list_clean.append(\"LINE_CHARGES_KEY\")\n",
    "            romlen_list_clean.append(\"0\")\n",
    "                                                    \n",
    "           except Exception as e:\n",
    "                                                    \n",
    "                 print(e)    \n",
    "                                                    \n",
    "           \n",
    "           try:\n",
    "                \n",
    "               df.withColumn(\"order_lineItems_charges_customAttributes\", explode_outer(\"order_lineItems_charges.customAttributes\"))  \n",
    "               df=df.withColumn(\"order_lineItems_charges_customAttributes\", explode_outer(\"order_lineItems_charges.customAttributes\"))  \n",
    "               df.select(\"*\",\n",
    "                         \"order_lineItems_charges_customAttributes.name\",\"order_lineItems_charges_customAttributes.value\")\n",
    "               df=df.select(\"*\",\n",
    "                    \"order_lineItems_charges_customAttributes.name\",\"order_lineItems_charges_customAttributes.value\")\n",
    "               df=df.withColumnRenamed(\"name\",\"CHARGES_CUST_ATTR_NAME\")  \n",
    "               df=df.withColumnRenamed(\"value\",\"CHARGES_CUST_ATTR_VALUE\")  \n",
    "              \n",
    "               df=df.withColumn(\"REFERENCE\", when(col(\"CHARGES_CUST_ATTR_NAME\") == \"Reference\", col(\"CHARGES_CUST_ATTR_VALUE\") ) )\n",
    "               df=df.drop(\"CHARGES_CUST_ATTR_NAME\")\n",
    "               df=df.drop(\"CHARGES_CUST_ATTR_VALUE\")\n",
    "               \n",
    "               jsonpathlist_clean.append(\"REFERENCE\")\n",
    "               rom_list_clean.append(\"REFERENCE\")\n",
    "               romlen_list_clean.append(\"100000\") \n",
    "            \n",
    "           except Exception as e:\n",
    "                                                    \n",
    "                 print(e)   \n",
    "                                                    \n",
    "           try:\n",
    "\n",
    "               df.select(\"order_lineItems_charges.detail.originalChargeAmount\")\n",
    "               #df=df.withColumn(\"ORIGINAL_CHARGE_AMT\", col(\"order_lineItems_charges.detail.originalChargeAmount\") ) \n",
    "            \n",
    "               jsonpathlist_clean.append(\"order_lineItems_charges.detail.originalChargeAmount\")\n",
    "               rom_list_clean.append(\"ORIGINAL_CHARGE_AMT\")\n",
    "               romlen_list_clean.append(\"100000\") \n",
    "      \n",
    "           except Exception as e:\n",
    "                         \n",
    "                 try:\n",
    "                      \n",
    "                     df.select(\"order_lineItems_charges.detail.amount\")\n",
    "                     #df=df.withColumn(\"ORIGINAL_CHARGE_AMT\", col(\"order_lineItems_charges.detail.amount\") ) \n",
    "                     jsonpathlist_clean.append(\"order_lineItems_charges.detail.amount\")\n",
    "                     rom_list_clean.append(\"ORIGINAL_CHARGE_AMT\")\n",
    "                     romlen_list_clean.append(\"100000\") \n",
    "\n",
    "                 except Exception as e:\n",
    "                           \n",
    "                           print(\"ORIGINAL_CHARGE_AMT not found....\")                         \n",
    "                           print(e)\n",
    "                                                    \n",
    "\n",
    "\n",
    "           return df, jsonpathlist_clean,rom_list_clean,romlen_list_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateDFSplFields_ROM_ORDER_LINE_STATUS_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n",
    "\n",
    "          df.select(\"order.sellerId\", \"order.id\", \"order_lineItems_sublineItems.sublineNo\", \n",
    "                     \"order_lineItems_charges.id\", \"order_lineItems_charges_discounts.id\" )\n",
    "          df = df.withColumn(\"ORDER_LINE_STATUS_KEY\", concat(col(\"order.sellerId\"), lit(\"-\"),  col(\"order.id\"),\n",
    "                 lit(\"-\"),  col(\"order_lineItems_sublineItems.sublineNo\"),\n",
    "                 lit(\"-\"),  col(\"order_lineItems_charges.id\"),\n",
    "                 lit(\"-\"),  col(\"order_lineItems_charges_discounts.id\") ))                                           \n",
    "                                                    \n",
    "          jsonpathlist_clean.append(\"ORDER_LINE_STATUS_KEY\")\n",
    "          rom_list_clean.append(\"ORDER_LINE_STATUS_KEY\") \n",
    "          romlen_list_clean.append(\"100000\")  \n",
    "            \n",
    "            \n",
    "          return df, jsonpathlist_clean,rom_list_clean,romlen_list_clean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateDFSplFields(df,tbl,jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    if ( tbl ==  \"KAFKARADIAL.ROM_ORDER_HEADER_STG0\" ):\n",
    "        \n",
    "       print(\"Accessing Special Fields from \"+tbl) \n",
    "        \n",
    "       df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_HEADER_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)\n",
    "                    \n",
    "        \n",
    "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_LINE_STG0\" ):\n",
    "        \n",
    "        print(\"Accessing Special Fields from \"+tbl) \n",
    "        \n",
    "        df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_LINE_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)\n",
    "        \n",
    "        \n",
    "    elif ( tbl == \"KAFKARADIAL.ROM_RELATED_ORDERS_STG0\" ):\n",
    "        \n",
    "        print(\"Accessing Special Fields from \"+tbl) \n",
    "        \n",
    "        df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_RELATED_ORDERS_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)\n",
    "                \n",
    "        \n",
    "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_PAYMENT_STG0\" ): \n",
    "        \n",
    "        print(\"Accessing Special Fields from \"+tbl) \n",
    "        \n",
    "        df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_PAYMENT_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)                              \n",
    "                                                         \n",
    "    \n",
    "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_PROMOTION_STG0\" ):  \n",
    "        \n",
    "        print(\"Accessing Special Fields from \"+tbl) \n",
    "        \n",
    "        df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_PROMOTION_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)\n",
    "                                                    \n",
    "    \n",
    "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_REFERENCES_STG0\" ): \n",
    "        \n",
    "        print(\"Accessing Special Fields from \"+tbl) \n",
    "                                                    \n",
    "        df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_REFERENCES_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)\n",
    "                                                    \n",
    "                                                 \n",
    "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_TAX_BREAKUP_STG0\" ):\n",
    "        \n",
    "        print(\"Accessing Special Fields from \"+tbl) \n",
    "                                                 \n",
    "        df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_TAX_BREAKUP_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)                                        \n",
    "                                                    \n",
    "                                                 \n",
    "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_LINE_RELATIONSHIP_STG0\" ):\n",
    "        \n",
    "         print(\"Accessing Special Fields from \"+tbl) \n",
    "         \n",
    "         df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_LINE_RELATIONSHIP_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)                                    \n",
    "                                                 \n",
    "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_CUSTOMER_INFO_STG0\" ):\n",
    "        \n",
    "            print(\"Accessing Special Fields from \"+tbl) \n",
    "            print(\"No Special Fields\")\n",
    "                                                 \n",
    "    elif  ( tbl == \"KAFKARADIAL.ROM_ORDER_LINE_CHARGES_STG0\" ):  \n",
    "        \n",
    "          print(\"Accessing Special Fields from \"+tbl) \n",
    "                                                    \n",
    "          df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_LINE_CHARGES_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)\n",
    "                                                 \n",
    "    elif  ( tbl == \"KAFKARADIAL.ROM_ORDER_LINE_STATUS_STG0\" ):\n",
    "        \n",
    "          print(\"Accessing Special Fields from \"+tbl) \n",
    "                                                 \n",
    "          df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_LINE_STATUS_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)                                      \n",
    "                                                 \n",
    "                                                 \n",
    "    return df,jsonpathlist_clean,rom_list_clean,romlen_list_clean     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDFXA(df,json_exploded_path_list,romlistfinal1,rom_col_len_list,epochId,tbl):\n",
    "    \n",
    "       print(\"&&&&&&&&&&\")\n",
    "       #df.show()\n",
    "       jsonpathlist_clean=[]\n",
    "       rom_list_clean = [] \n",
    "       romlen_list_clean = []\n",
    "       dfbadlist=[]\n",
    "       \n",
    "       #df.registerTempTable(\"Order_Created\")\n",
    "        \n",
    "       for elm,colval,collen in zip(json_exploded_path_list,romlistfinal1,rom_col_len_list):\n",
    "        \n",
    "           try:\n",
    "             df.select(elm)                 \n",
    "             jsonpathlist_clean.append(elm)\n",
    "             rom_list_clean.append(colval)  \n",
    "             romlen_list_clean.append(collen)\n",
    "           except Exception as e:\n",
    "             #print(e)\n",
    "             print(elm)\n",
    "            \n",
    "            \n",
    "           \n",
    "       try:\n",
    "            df.select(\"topicName\",\"partition\",\"offset\")\n",
    "            df = df.withColumn(\"DW_SOURCE_ID\" , concat(col(\"topicName\"), lit(\"-\"), lit(datetime.now()), lit(\"-\"), col(\"partition\"), lit(\"-\"), col(\"offset\") ))\n",
    "            jsonpathlist_clean.append(\"DW_SOURCE_ID\")\n",
    "            rom_list_clean.append(\"DW_SOURCE_ID\")\n",
    "            romlen_list_clean.append(\"0\")\n",
    "        \n",
    "       except Exception as e:\n",
    "        \n",
    "            print(\" Can't obtain DW_SOURCE_ID \")\n",
    "            print(e)\n",
    "    \n",
    "            \n",
    "            \n",
    "       df,jsonpathlist_clean,rom_list_clean,romlen_list_clean= updateDFSplFields(df,tbl,jsonpathlist_clean,rom_list_clean, romlen_list_clean)\n",
    "             \n",
    "             \n",
    "       # for elm,colval,collen in zip(jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n",
    "        \n",
    "       #     try:\n",
    "               \n",
    "       #       if (tbl==\"KAFKARADIAL.ROM_ORDER_PAYMENT_STG0\"):\n",
    "       #           #df.show()\n",
    "       #           #df.select(elm).show()\n",
    "       #           #print(length(df.select(elm).collect()[0][0]))  \n",
    "       #           print(\"here\")\n",
    "               \n",
    "               \n",
    "       #       if collen != \"INTEGER\":  \n",
    "       #           #df=df.withColumn(colval, when(length(col(colval)) > collen,substring(col(colval), 1, collen )        .otherwise(col(colval))))\n",
    "       #            df=df.withColumn(colval, when(length(col(colval).cast(\"string\")) > collen,substring(col(colval).cast(\"string\"), 1, collen )        .otherwise(col(colval))))\n",
    "\n",
    "       #     except Exception as e:\n",
    "       #       print(e)\n",
    "       #       print(colval)\n",
    "              \n",
    "       \n",
    "       cdf=df.select(jsonpathlist_clean)\n",
    "       #cdf.show()\n",
    "            \n",
    "       sdf=cdf.toDF(*rom_list_clean)\n",
    "       #sdf.show()\n",
    "         \n",
    "    \n",
    "       ######## Update Dataframe ########\n",
    "       print(\"Updating\")\n",
    "       sdf = updateDF(sdf,tbl)\n",
    "       #sdf.show()\n",
    "    \n",
    "    \n",
    "       ##### Remove Duplicates ########\n",
    "       print(\"Dropping Duplicates\")\n",
    "       #tbl_pkeys=pk_dict.get(tbl)\n",
    "       #inaldf=sdf.dropDuplicates(tbl_pkeys)\n",
    "       finaldf=sdf\n",
    "       \n",
    "      \n",
    "       #writeToSQLWarehouse(dfb,epochId,\"INSERT_FAILED_MSG\")\n",
    "       \n",
    "    \n",
    "       #finaldf=sdf.dropDuplicates([\"ORDER_ID\"])\n",
    "       #finaldf=sdf.withColumn(\"MERGEDCOL\",hash(concat(*rom_list_clean)))\n",
    "       #finaldf.show()\n",
    "       #finaldf=finaldf.dropDuplicates(['MERGEDCOL'])\n",
    "       #finaldf.show()\n",
    "       #finaldf=finaldf.drop('MERGEDCOL')\n",
    "       #finaldf.show()\n",
    "       #finaldf=sdf.distinct()\n",
    "       #finaldf=sdf.groupBy(rom_list_clean).count.sort().show\n",
    "       #print(sdf)\n",
    "       #finaldf.printSchema()\n",
    "    \n",
    "       return finaldf,dfbadlist,romlen_list_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query1 = df     .writeStream     .outputMode(\"append\")    .option(\"partition.assignment.strategy\", \"range\")    .foreachBatch(popTablesBlkAtomicNew)    .start()\n",
    "\n",
    "\n",
    "#query1 = df     .writeStream     .outputMode(\"append\")    .option(\"checkpointLocation\", \"/myapp/GChkPt11\")    .option(\"partition.assignment.strategy\", \"range\")    .foreachBatch(popTablesBlkAtomicNew)    .start()\n",
    "    \n",
    "query1.awaitTermination(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while ( (query1.status['isDataAvailable'] == True) and (query1.status['isTriggerActive'] == True) ):\n",
    "    \n",
    "    query1.status\n",
    "    \n",
    "query1.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
