{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pyspark\n", "from pyspark.sql import SparkSession"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql.functions import*\n", "from pyspark.sql.types import*\n", "import time"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import re\n", "import pandas as pd \n", "import traceback\n", "import sys\n", "from time import sleep\n", "import traceback\n", "import smtplib\n", "from collections import defaultdict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import ibm_db\n", "import ibm_db_dbi\n", "#import ibm_db_sa\n", "from datetime import datetime, date, time\n", "import pyspark.sql.functions as func\n", "from pyspark.sql.functions import broadcast\n", "from pyspark.sql import Window\n", "#import pip\n", "import subprocess\n", "from pathlib import Path"]}, {"cell_type": "markdown", "metadata": {}, "source": ["def install(package):<br>\n", "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" \n", " \n", "# try:    \n", " \n", "#   install('pymysql')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  import pymysql"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  \n", "# except Exception as e:\n", "    \n", "#     print(e)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sys.path.append('/myapp/python/packages')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pymysql\n", "# In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark = SparkSession.builder.getOrCreate()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import logging"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["flpath = '/myapp/consolelogs/sample'+str(datetime.now())+'.log'\n", "logging.basicConfig(level=logging.INFO, filename=flpath)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loggerpy = logging.getLogger(__name__)  "]}, {"cell_type": "markdown", "metadata": {}, "source": ["###### Grab the Arguments #########"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"**Arg*****\")\n", "argslist = sys.argv\n", "print(argslist)\n", "print(len(argslist))\n", "print(\"********\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#########   Check for Lock File #############"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["my_file = Path(argslist[7])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["while my_file.exists():\n", "    \n", "    print(\"Old App still running... Lock File Exists....\")\n", "    sleep(10)\n", "    #sys.exit(0)\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Creates a Lock File ####### "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.mknod(my_file)\n", "    \n", "tbllist=[]\n", "jsonpathlists=[]\n", "colslist=[]\n", "json_exploded_path_lists=[]\n", "col_len_lists=[]\n", "jsonmapfilepath = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["jdbcUrl=\"\"\n", "singlestoreuser=\"\"\n", "singlestorepassword=\"\"\n", "jdbcstr=\"\"\n", "kafka_bootstrap_servers=\"\"\n", "scram_user=\"\"\n", "scram_pass=\"\"\n", "truststore_location=\"\"\n", "truststore_password=\"\"\n", "cp4dcfginfopath = \"\"\n", "kafkatopic = \"\" \n", "singlestoreurl = \"\"\n", "singlestoreport = \"\"\n", "singlestoredb = \"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["######## Function to Send Email #########"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sendmail(sub, body):\n", "    try:\n", "       SERVER = \"us.relay.ibm.com\"\n", "       #SERVER = \"smtp.gmail.com\"\n", "       #SERVER = smtplib.SMTP('smtp.gmail.com', 587)\n", "       #SERVER.ehlo()\n", "       FROM = \"romdbload@radial.com\"\n", "       TO = [\"mlakshm@us.ibm.com\"] # must be a list\n", "       SUBJECT = sub\n", "       TEXT = body\n", "       message = 'From:'+FROM+       '\\nTo: '+\", \".join(TO)+       '\\nSubject: '+SUBJECT+'\\n'+TEXT\n", "       print(message)\n", "       server = smtplib.SMTP(SERVER)\n", "       server.sendmail(FROM, TO, message)\n", "       server.quit()\n", "       return 0\n", "    except Exception as e:\n", "       exp_tb=traceback.format_exc()\n", "       print(exp_tb)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def  readMappingInfo(tbllist, jsonpathlists, colslist, json_exploded_path_lists, col_len_lists, jsonmapfilepath):\n", "    \n", "    print(\"Read Mapping Info.....\")\n", "    jsonmapfilepath =  argslist[1]\n", "    \n", "    with open(jsonmapfilepath) as f:\n", "        contents = f.read()\n", "        contents=contents.strip()\n", "        maplist=contents.split(\"TABLE_NAME:\")\n", "        #print(maplist)\n", "        #maplist = list(filter([], maplist))\n", "        for lmap in maplist:\n", "        \n", "            lmaplist=lmap.split(\"\\n\")\n", "            #lmaplist = list(filter(None, lmaplist))\n", "            tbl=lmaplist.pop(0)\n", "            tbllist.append(tbl)\n", "            collist=[]\n", "            jsonpathlist=[]\n", "            json_exploded_path_list=[]\n", "            col_len_list=[]\n", "        \n", "            for col_json in lmaplist:\n", "               coljsonarr=col_json.split(\",\")\n", "               if (len(coljsonarr)==4):\n", "                    collist.append(coljsonarr[0])\n", "                    jsonpathlist.append(coljsonarr[1])\n", "                    json_exploded_path_list.append(coljsonarr[2])\n", "                    col_len_list.append(coljsonarr[3])\n", "               \n", "                \n", "            colslist.append(collist)\n", "            jsonpathlists.append(jsonpathlist)\n", "            json_exploded_path_lists.append(json_exploded_path_list)\n", "            col_len_lists.append(col_len_list)\n", "            \n", "            \n", "    f.close()\n", "    \n", "    \n", "    tbllist = [x for x in tbllist if x != 'KAFKARADIAL.']\n", "    tbllist = [x for x in tbllist if x != '']\n", "    colslist = [x for x in colslist if x != []]\n", "    jsonpathlists = [x for x in jsonpathlists if x != []]\n", "    json_exploded_path_lists = [x for x in json_exploded_path_lists if x != []]\n", "    col_len_lists = [x for x in col_len_lists if x != []]\n", "    \n", "    \n", "    return tbllist, colslist, jsonpathlists, json_exploded_path_lists, col_len_lists\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def readConfigInfo(jdbcUrl, singlestoreuser, singlestorepassword, jdbcstr, kafka_bootstrap_servers, scram_user, scram_pass, truststore_location, truststore_password, kafkatopic, singlestoreurl, singlestoreport, singlestoredb):\n", "    \n", "    print(\"Read Config Info.....\")\n", "    \n", "    cp4dcfginfopath = argslist[2]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    with open(cp4dcfginfopath) as f:\n", "    \n", "        contents = f.read()\n", "        contents=contents.strip()\n", "        cfg_infolist=contents.split(\"\\n\")\n", "        jdbcUrl=cfg_infolist[0]\n", "        singlestoreuser=cfg_infolist[1]\n", "        singlestorepassword=cfg_infolist[2]\n", "        jdbcstr=cfg_infolist[3]\n", "        kafka_bootstrap_servers=cfg_infolist[4]\n", "        scram_user=cfg_infolist[5]\n", "        scram_pass=cfg_infolist[6]\n", "        truststore_location=cfg_infolist[7]\n", "        truststore_password=cfg_infolist[8]\n", "        kafkatopic=cfg_infolist[9]\n", "        singlestoreurl=cfg_infolist[10]\n", "        singlestoreport=int(cfg_infolist[11])\n", "        singlestoredb=cfg_infolist[12]\n", "        \n", "        \n", "    f.close()    \n", "    \n", "    \n", "    \n", "    return jdbcUrl, singlestoreuser, singlestorepassword, jdbcstr, kafka_bootstrap_servers, scram_user, scram_pass, truststore_location, truststore_password, kafkatopic, singlestoreurl, singlestoreport, singlestoredb\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    tbllist, colslist, jsonpathlists, json_exploded_path_lists, col_len_lists = readMappingInfo(tbllist, jsonpathlists, colslist, json_exploded_path_lists, col_len_lists, jsonmapfilepath)\n", "    print(tbllist)\n", "    print(colslist)\n", "    print(jsonpathlists)\n", "    print(json_exploded_path_lists)\n", "    print(col_len_lists)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    print(jdbcUrl)\n", "    print(singlestoreuser)\n", "    print(singlestorepassword)\n", "    print(jdbcstr)\n", "    print(kafka_bootstrap_servers)\n", "    print(scram_user)\n", "    print(scram_pass)\n", "    print(truststore_location)\n", "    print(truststore_password)\n", "    print(kafkatopic)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    jdbcUrl, singlestoreuser, singlestorepassword, jdbcstr, kafka_bootstrap_servers, scram_user, scram_pass, truststore_location, truststore_password, kafkatopic, singlestoreurl, singlestoreport, singlestoredb  \\\n", "     =  readConfigInfo(jdbcUrl, singlestoreuser, singlestorepassword, jdbcstr, kafka_bootstrap_servers, scram_user, scram_pass, truststore_location, truststore_password, kafkatopic, singlestoreurl, singlestoreport, singlestoredb)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    jsonschemafilepath = argslist[3]\n", "    jsondf = spark.read.json(jsonschemafilepath, multiLine=True)\n", "    order_created_schema=jsondf.schema"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    jsondf.printSchema()\n", "    arraysdf = pd.read_csv(argslist[4], sep=\",\")\n", "    \n", "except Exception as e:\n", "    \n", "    print(e)\n", "    os.remove(argslist[7])\n", "    sys.exit(1)\n", "    \n", "  \n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def createCleanLists(df, json_exploded_path_lists,colslist,col_len_lists,tbllist):\n", "    \n", "    \n", "    jsonpathlists_clean = []\n", "    rom_lists_clean = []\n", "    romlen_lists_clean = []\n", "    \n", "    \n", "    for json_exploded_path_list,romlistfinal1,rom_col_len_list, tbl in zip(json_exploded_path_lists,colslist,col_len_lists,tbllist):\n", " \n", "       jsonpathlist_clean = []\n", "       rom_list_clean = []\n", "       romlen_list_clean = []\n", "        \n", "       for elm,colval,collen in zip(json_exploded_path_list,romlistfinal1,rom_col_len_list):\n", "        \n", "            try:\n", "              df.select(elm)\n", "              jsonpathlist_clean.append(elm)\n", "              rom_list_clean.append(colval)  \n", "              romlen_list_clean.append(collen)\n", "            except Exception as e:\n", "              #print(e)\n", "              log.warn(elm)\n", "              print(elm)\n", "              \n", "       jsonpathlists_clean.append(jsonpathlist_clean)   \n", "       rom_lists_clean.append(rom_list_clean)\n", "       romlen_lists_clean.append(romlen_list_clean)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    return jsonpathlists_clean, rom_lists_clean, romlen_lists_clean"]}, {"cell_type": "markdown", "metadata": {}, "source": ["son_exploded_path_lists,colslist,col_len_lists = createCleanLists(jsondf, json_exploded_path_lists,colslist,col_len_lists,tbllist)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rint(\"Starting to readstream....\")<br>\n", "rint(json_exploded_path_lists,colslist,col_len_lists)<br>\n", "rint(datetime.now())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["dfi = spark \\<br>\n", "  .readStream \\<br>\n", "  .format(\"kafka\") \\<br>\n", "  .option(\"kafka.bootstrap.servers\", \"minimal-prod-kafka-bootstrap-cp4i.itzroks-270006dwv1-tdbuym-6ccd7f378ae819553d37d5f2ee142bd6-0000.us-south.containers.appdomain.cloud:443\") \\<br>\n", "  .option(\"kafka.sasl.jaas.config\",\"org.apache.kafka.common.security.scram.ScramLoginModule required username='cred2' password='yRenuVTcidCV';\") \\<br>\n", "  .option(\"kafka.security.protocol\", \"SASL_SSL\") \\<br>\n", "  .option(\"kafka.sasl.mechanism\", \"SCRAM-SHA-512\") \\<br>\n", "  .option(\"kafka.ssl.truststore.location\",\"/myapp/es-cert.jks\") \\<br>\n", "  .option(\"kafka.ssl.truststore.password\", \"JCi4nt0DkN9B\") \\<br>\n", "  .option(\"kafka.ssl.protocol\", \"TLSv1.2\") \\<br>\n", "  .option(\"kafka.ssl.enabled.protocols\", \"TLSv1.2\") \\<br>\n", "  .option(\"kafka.ssl.endpoint.identification.algorithm\", \"HTTPS\") \\<br>\n", "  .option(\"failOnDataLoss\", \"false\") \\<br>\n", "#   .option(\"assign\", \n{\"gtest50p\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49]}\n) \\<br>\n", "#   .load() \\<br>\n", "#   .select(col(\"partition\").cast(\"string\"),col(\"offset\").cast(\"string\"),col(\"value\").cast(\"string\"),from_json(col(\"value\").cast(\"string\"), order_created_schema))<br>\n", "  #.option(\"assign\", \n{\"gtest50p\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49]}\n) \\"]}, {"cell_type": "markdown", "metadata": {}, "source": ["dfi.printSchema()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    \n", "dfi = spark \\\n", "  .readStream \\\n", "  .format(\"kafka\") \\\n", "  .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n", "  .option(\"kafka.sasl.jaas.config\",\"org.apache.kafka.common.security.scram.ScramLoginModule required username=\"+scram_user+\" password=\"+scram_pass+\";\") \\\n", "  .option(\"kafka.security.protocol\", \"SASL_SSL\") \\\n", "  .option(\"kafka.sasl.mechanism\", \"SCRAM-SHA-512\") \\\n", "  .option(\"kafka.ssl.truststore.location\",truststore_location) \\\n", "  .option(\"kafka.ssl.truststore.password\", truststore_password) \\\n", "  .option(\"kafka.ssl.protocol\", \"TLSv1.2\") \\\n", "  .option(\"kafka.ssl.enabled.protocols\", \"TLSv1.2\") \\\n", "  .option(\"kafka.ssl.endpoint.identification.algorithm\", \"HTTPS\") \\\n", "  .option(\"failOnDataLoss\", \"false\") \\\n", "  .option(\"assign\", \"\"\"{\"\"\"+kafkatopic+\"\"\"}\"\"\") \\\n", "  .load() \\\n", "  .select(col(\"partition\").cast(\"string\"),col(\"offset\").cast(\"string\"),col(\"value\").cast(\"string\"),from_json(col(\"value\").cast(\"string\"), order_created_schema))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  \n", "dfi.printSchema()\n", " \n", " \n", "# In[ ]:\n", " "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def writeToSQLWarehouse(jdf,epochId,tbl,conn):\n", "  \n", "  print(tbl)\n", "  insertLogs(\"INFO\",\"Writing to table \"+tbl, conn)  \n", "  #print(df)\n", "  print(\"hgjghjgh\")\n", "  #jdf.show()\n", "  jdf.write.format(\"singlestore\") \\\n", "  .mode(\"overwrite\") \\\n", "  .option(\"loadDataCompression\", \"LZ4\") \\\n", "  .option(\"ddlEndpoint\", jdbcUrl) \\\n", "  .option(\"user\", singlestoreuser) \\\n", "  .option(\"password\", singlestorepassword) \\\n", "  .save(tbl)\n", "  insertLogs(\"INFO\",\"Completed writing to table \"+tbl, conn)  \n", "  print(\"jhghjgjn\")\n", "  #jdf.write.format(\"jdbc\")   .mode(\"append\")   .option(\"url\", jdbcUrl)   .option(\"dbtable\", tbl)   .option(\"user\", user)   .option(\"password\", password)   .save()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def explodeDF(df):\n", "    \n", "    df=df.withColumn(\"order\", df.mvalue.order)\n", "    df=df.withColumn(\"customAttributes\", df.mvalue.customAttributes)\n", "    df=df.withColumn(\"topicName\", df.mvalue.topicName)\n", "    df=df.drop(\"mvalue\")\n", "    df=df.drop(\"value\")\n", "    #df.show()\n", "    \n", "    for i, row in arraysdf.iterrows():\n", "    \n", "     try:\n", "            \n", "        json_path_to_explode=row['JSON_PATH_TO_EXPLODE']\n", "        json_path_exploded=row['JSON_PATH_EXPLODED']\n", "        print(json_path_to_explode)\n", "        print(json_path_exploded)\n", "    \n", "        df=df.withColumn(json_path_exploded,explode_outer(json_path_to_explode))\n", "        #df.show()\n", "        \n", "     except Exception as e:\n", "         \n", "        print(e)\n", "        \n", "    \n", "    return df"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def insertBatch(df,epochId):\n", "    \n", "    tbl=\"KAFKARADIAL.INSERT_BATCH\"\n", "    \n", "    fdf=df.select(\"mvalue.order.id\",\"partition\",\"offset\",\"value\")\n", "    fdf=fdf.withColumnRenamed(\"id\", \"ORDER_ID\")\n", "    fdf=fdf.withColumnRenamed(\"partition\", \"MSG_PARTITION\") \n", "    fdf=fdf.withColumnRenamed(\"offset\", \"MSG_OFFSET\") \n", "    fdf=fdf.withColumnRenamed(\"value\", \"MSG_VALUE\") \n", "    \n", "    writeToSQLWarehouse(fdf, epochId, tbl, conn)      \n", "    \n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def insertFailedBatch(df,epochId,conn):\n", "    \n", "    tbl=\"KAFKARADIAL.INSERT_FAILED_BATCH\"\n", "    \n", "    fdf=df.select(\"value\")\n", "    fdf=fdf.withColumnRenamed(\"value\", \"MSG_VALUE\") \n", "    \n", "    writeToSQLWarehouse(fdf, epochId, tbl, conn)    \n", "    \n", "    \n", "def connToMySQL():\n", "    \n", "    \n", "    conn = pymysql.connect(\n", "    user=singlestoreuser,\n", "    password=singlestorepassword,\n", "    host=singlestoreurl,\n", "    port=singlestoreport,\n", "    database=singlestoredb, autocommit=True)\n", "    print(\"Connected to PYMYSQL\")\n", "    return conn\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def insertLogs(qtyp, qmsg, conn):\n", "    \n", "    \n", "     qmsg = qmsg.replace(\"'\", \"''\")    \n", "     qry=\"INSERT INTO KAFKARADIAL.ROM_LOGS (LOG_TYPE, LOG_MSG) VALUES ('\"+qtyp+\"','\"+qmsg+\"');\"\n", "     print(qry)\n", "    \n", "     conn.query(qry)\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def prepareData(dfblk,json_exploded_path_lists,colslist,col_len_lists,epochId,tbllist,conn):\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  finaldflist=[]\n", "  \n", "  \n", "  print(\"Starting to Prepare DF List:........\")\n", "  insertLogs(\"INFO\",\"Starting to Prepare DF List:........\", conn)  \n", "  print(datetime.now())   \n", "  timestamp = datetime.now() \n", "  timestr = str(timestamp)\n", "  \n", "  dfblk,json_exploded_path_lists,colslist,col_len_lists = addGenereicSplFields(dfblk,json_exploded_path_lists,colslist,col_len_lists,timestr)\n", "  \n", "  \n", "  for json_exploded_path_list,romlistfinal1,rom_col_len_list, tbl in zip(json_exploded_path_lists,colslist,col_len_lists,tbllist):\n", "    \n", "    #dfblk.persist()   \n", "    finaldf,col_len_list=prepareDFXA(dfblk,json_exploded_path_list,romlistfinal1,rom_col_len_list,epochId,tbl,conn) \n", "    #dfblk.unpersist()\n", "    #finaldflist.append(finaldf)\n", "    \n", "    if len(finaldf.dtypes) == 0:\n", "     \n", "       print(\"Empty DF\")\n", "       insertLogs(\"INFO\",\"Empty Dataframe\", conn)  \n", "    else: \n", "        \n", "       print(\"******************************\")\n", "       print(\"Non Empty DF\")\n", "       insertLogs(\"INFO\",\"Non Empty Dataframe\", conn)  \n", "       print(\"******************************\") \n", "       #finaldf.show()\n", "       writeToSQLWarehouse(finaldf, epochId, tbl, conn)\n", "        \n", "  # ordiddf=dfblk.select(\"order.id\")  \n", "  # writeToSQLWarehouse(ordiddf, epochId, tbl)\n", "  \n", "  #return finaldflist\n", "  print(\"Ending to Prepare DF List:........\")\n", "  print(datetime.now()) \n", "  insertLogs(\"INFO\",\"Ending to Prepare DF List:........\", conn)  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def popTablesBlkAtomicNewTest(df, epochId):\n", "    df=df.withColumnRenamed(\"from_json(CAST(value AS STRING))\", \"mvalue\") \n", "    insertBatch(df,epochId)    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def popTablesBlkAtomicNew(df, epochId):  #### Bulk Insert\n", "      \n", "   conn = connToMySQL()\n", "   qmsg=str(datetime.now())\n", "   insertLogs(\"INFO\",qmsg, conn)  \n", "   #####  Create JDBC Connection #######\n", "   print(datetime.now())\n", "   #df.coalesce(4)\n", "   df.persist()   \n", "   #df.coalesce(16) \n", "   df.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["   \n", "   \n", "   try:\n", "    \n", "    \n", "    if df.rdd.isEmpty():\n", "       print(df.rdd.isEmpty)\n", "    else:\n", "      #df.show()\n", "      df=df.withColumnRenamed(\"from_json(CAST(value AS STRING))\", \"mvalue\") \n", "      #insertBatch(df,epochId)   \n", "    \n", "      if df.rdd.isEmpty():\n", "       print(df.rdd.isEmpty)\n", "    \n", "      else:\n", "    \n", "         ###### Exploding Dataframe #######\n", "         print(\"Starting to Explode Data:........\")\n", "         insertLogs(\"INFO\",\"Starting to Explode Data:........\", conn) \n", "         print(datetime.now()) \n", "         dfblk=explodeDF(df) \n", "         #dfblk.show()\n", "         print(\"Finished Exploding Data:........\")\n", "         insertLogs(\"INFO\",\"Finished Exploding Data:........\", conn) \n", "         print(datetime.now()) \n", "      \n", "          \n", "         ##### Prepare Blk Dataframe & Insert Queries  #######\n", "          \n", "         #qlist,finaldflist=prepareData(dfblk,json_exploded_path_lists,colslist,epochId,tbllist)\n", "         #qlist,finaldflist,dictlist,colslistup=prepareData(dfblk,json_exploded_path_lists,colslist,col_len_lists,epochId,tbllist)\n", "         print(\"Starting to Prepare Data:........\")\n", "         insertLogs(\"INFO\",\"Starting to Prepare Data:........\", conn) \n", "         print(datetime.now())  \n", "         #qlist=prepareData(dfblk,json_exploded_path_lists,colslist,col_len_lists,epochId,tbllist)\n", "         prepareData(dfblk,json_exploded_path_lists,colslist,col_len_lists,epochId,tbllist, conn)\n", "         success_df = df.select(\"mvalue.order.id\")\n", "         success_df = success_df.withColumnRenamed(\"id\",\"ORDER_ID\")\n", "         writeToSQLWarehouse(success_df, epochId, \"KAFKARADIAL.SUCCESS_ORDERS\", conn)\n", "         #print(xyz)\n", "         print(\"Finishing to Write Data:.......\")\n", "         insertLogs(\"INFO\",\"Finishing to Write Data:.......\", conn) \n", "         #print(qlist)\n", "         print(\"*****\")\n", "   \n", "       \n", "    \n", "   except Exception as e:\n", "          print(\"here...........\")\n", "          insertLogs(\"ERROR\",\"Inside Exception.......\", conn) \n", "          print(type(e))\n", "          insertLogs(\"ERROR\",str(e), conn) \n", "          exp_tb=traceback.format_exc()\n", "          #print(expk)\n", "          insertLogs(\"ERROR\",str(exp_tb), conn) \n", "          insertFailedBatch(df,epochId, conn)\n", "          #popTablesAtomicUpdated(df, epochId, conn)\n", "          \n", "   finally:\n", "          print(\"Complete\")\n", "          insertLogs(\"INFO\",\"Batch Complete\", conn) \n", "          df.unpersist()\n", "          if conn==True:\n", "              conn.close()\n", "              #print(conn)\n", "              #ibm_db.close(conn)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    \n", "    \n", "def addGenereicSplFields(df,json_exploded_path_lists,colslist,col_len_lists,timestr):\n", "    \n", "    try:\n", "        \n", "        df = df.withColumn(\"DW_SOURCE_ID\" , concat(col(\"topicName\"), lit(\"-\"), lit(timestr), lit(\"-\"), col(\"partition\"), lit(\"-\"), col(\"offset\") ))\n", "        for json_exploded_path_list,romlistfinal1,rom_col_len_list in zip(json_exploded_path_lists,colslist,col_len_lists):\n", "            json_exploded_path_list.append(\"DW_SOURCE_ID\")\n", "            romlistfinal1.append(\"DW_SOURCE_ID\")\n", "            rom_col_len_list.append(\"100000000\")  \n", "        \n", "    except Exception as e:\n", "        \n", "        print(\" Can't obtain DW_SOURCE_ID \")\n", "        print(e) \n", "        \n", "        \n", "    df = addPayDFSplFields_ROM_ORDER_PAYMENT_STG0(df)   \n", "        \n", "    \n", "    return df,json_exploded_path_lists,colslist,col_len_lists   "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def updateDF(sdf,tbl):\n", "    \n", "    #sdf.printSchema()\n", "    if tbl==\"KAFKARADIAL.ROM_ORDER_LINE_STG0\":\n", "       try:\n", "        sdf=sdf.withColumn(\"IS_ASSOCIATE_DELIVERY\", when(col(\"IS_ASSOCIATE_DELIVERY\") == \"false\",lit(\"0\") )        .when(col(\"IS_ASSOCIATE_DELIVERY\") == \"true\",lit(\"1\"))         .otherwise(col(\"IS_ASSOCIATE_DELIVERY\")))\n", "       except Exception as e:\n", "         print(e)\n", "    \n", "    return sdf"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    \n", "############################  TABLE UPDATES  #############################   "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def updateDFSplFields_ROM_ORDER_HEADER_STG0(df, jsonpathlist_clean, rom_list_clean, romlen_list_clean):\n", "    \n", "    \n", "        try:\n", "        \n", "            df = df.withColumn(\"ORDER_HEADER_KEY\", concat(col(\"order.sellerId\"), lit(\"-\"), col(\"order.id\")))\n", "            jsonpathlist_clean.append(\"ORDER_HEADER_KEY\")\n", "            rom_list_clean.append(\"ORDER_HEADER_KEY\")\n", "            romlen_list_clean.append(\"1000000\")\n", "            \n", "        except Exception as e:\n", "            \n", "             print(\" Can't obtain ORDER_HEADER_KEY \")\n", "             print(e)\n", "        \n", "        \n", "        try: \n", "    \n", "           df.select(\"order.hfrNumber\")\n", "           #df=df.withColumn(\"HFR_NUMBER\" , col(\"order.hfrNumber\") )\n", "           jsonpathlist_clean.append(\"order.hfrNumber\")\n", "           rom_list_clean.append(\"HFR_NUMBER\")\n", "           romlen_list_clean.append(\"100000\") \n", "        except Exception as e:\n", "    \n", "            try:\n", "        \n", "                df.select(\"order.raNumber\")\n", "                #df=df.withColumn(\"HFR_NUMBER\" , col(\"order.raNumber\") )\n", "                jsonpathlist_clean.append(\"order.raNumber\")\n", "                rom_list_clean.append(\"HFR_NUMBER\")\n", "                romlen_list_clean.append(\"100000\")\n", "        \n", "            except Exception as e:\n", "        \n", "                print(\" HFR NUMBER order.hfrNumber or order.raNumber NOT PRESENT \")\n", "            \n", "            \n", "        try: \n", "    \n", "           df.select(\"order.billingAddressRefId\")\n", "           #df=df.withColumn(\"BILL_TO_KEY\" , col(\"order.billingAddressRefId\") )\n", "           jsonpathlist_clean.append(\"order.billingAddressRefId\")\n", "           rom_list_clean.append(\"BILL_TO_KEY\")\n", "           romlen_list_clean.append(\"100000\") \n", "        except Exception as e:\n", "        \n", "            print(\" BILL_TO_KEY -->  order.billingAddressRefId NOT PRESENT \")\n", "            \n", "            \n", "        return df, jsonpathlist_clean, rom_list_clean,romlen_list_clean\n", "    \n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def updateDFSplFields_ROM_ORDER_LINE_STG0(df, jsonpathlist_clean,rom_list_clean,romlen_list_clean ):\n", "    \n", "    \n", "    \n", "        try:\n", "        \n", "            df = df.withColumn(\"ORDER_LINE_KEY\", concat(col(\"order.sellerId\"), lit(\"-\"), col(\"order.id\"), lit(\"-\"), col(\"order_lineItems.lineNo\") ))\n", "            jsonpathlist_clean.append(\"ORDER_LINE_KEY\")\n", "            rom_list_clean.append(\"ORDER_LINE_KEY\")\n", "            romlen_list_clean.append(\"1000000\")\n", "            \n", "        except Exception as e:\n", "            \n", "              print(\" Can't obtain ORDER_LINE_KEY \")\n", "              print(e)\n", "    \n", "    \n", "        try: \n", "            \n", "            \n", "           #df2 = df.groupBy(col(\"order.id\"), col(\"order_lineItems_sublineItems.quantity\")).sum(\"order_lineItems_sublineItems.quantity\")\n", "           #df2 = df2.withColumnRenamed(\"sum(order_lineItems_sublineItems.quantity AS `quantity`)\", \"ORDERED_QTY\") \n", "           \n", "           #df=df.alias('a').join(df2.alias('b'),col('b.id') == col('a.order.id')).select(\"a.*\",\"b.ORDERED_QTY\")\n", "            \n", "           df2 = df.groupBy(col(\"order.id\"), col(\"order_lineItems\"),col(\"order_lineItems_sublineItems\")).count()\n", "           #df2 = df2.coalesce(8)\n", "           df2 = df2.groupBy(\"id\",\"order_lineItems\").agg(sum('order_lineItems_sublineItems.quantity').alias(\"ORDERED_QTY\"))\n", "           #df = df.withColumn(\"ORDERED_QTY\", func.sum(\"order_lineItems_sublineItems.quantity\") \\\n", "           #                          .over(Window.partitionBy(\"order_lineItems\"))) \n", "           df2.select(\"*\",\"order_lineItems_sublineItems.quantity\").show()\n", "           df=df.alias('a').join(broadcast(df2.alias('b')),col('b.id') == col('a.order.id'),\"left\").select(\"a.*\",\"b.ORDERED_QTY\")\n", "            \n", "           \n", "           \n", "           jsonpathlist_clean.append(\"ORDERED_QTY\")\n", "           rom_list_clean.append(\"ORDERED_QTY\")\n", "           romlen_list_clean.append(\"100000\") \n", "            \n", "        except Exception as e:\n", "            print(e)\n", "            try:\n", "                df.select(\"order_lineItems.quantity\")\n", "                \n", "                #df = df.groupBy(col(\"order.id\"), col(\"order_lineItems.quantity\")).sum(\"order_lineItems.quantity\")\n", "                #df = df.withColumnRenamed(\"sum(order_lineItems.quantity AS `quantity`)\", \"ORDERED_QTY\") \n", "                jsonpathlist_clean.append(\"order_lineItems.quantity\")\n", "                rom_list_clean.append(\"ORDERED_QTY\")\n", "                romlen_list_clean.append(\"10000\")\n", "                \n", "            except Exception as e:    \n", "                print(e)\n", "                print(\" ORDERED_QTY not present \")\n", "                \n", "                 \n", "        try: \n", "           print(\"********\")\n", "           #df.show()\n", "           df.select(\"order_lineItems.shippingAddressRefId\")\n", "           #df=df.withColumn(\"SHIP_TO_KEY\" , col(\"order_lineItems.shippingAddressRefId\") )\n", "           jsonpathlist_clean.append(\"order_lineItems.shippingAddressRefId\")\n", "           rom_list_clean.append(\"SHIP_TO_KEY\")\n", "           romlen_list_clean.append(\"100000\") \n", "        except Exception as e:\n", "            print(e)\n", "            print(\" SHIP_TO_KEY -->  order_lineItems.shippingAddressRefId NOT PRESENT \")\n", "            \n", "    \n", "        return df, jsonpathlist_clean,rom_list_clean,romlen_list_clean\n", "        "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def updateDFSplFields_ROM_RELATED_ORDERS_STG0( df,jsonpathlist_clean,rom_list_clean,romlen_list_clean ):\n", "    try: \n", "            df.select(\"order.id\",\"order.sellerId\",\"order_relatedOrders.id\",\"order_relatedOrders_relatedLines.lineNo\",\"order_relatedOrders_relatedLines.originalLineNo\" )\n", "            df = df.withColumn(\"RELATED_ORDER_KEY\", concat(col(\"order.id\"), lit(\"-\"), col(\"order.sellerId\"), \n", "                 lit(\"-\"),  col(\"order_relatedOrders.id\"),  lit(\"-\"), col(\"order_relatedOrders_relatedLines.lineNo\"),\n", "                 lit(\"-\"),  col(\"order_relatedOrders_relatedLines.originalLineNo\")    ))\n", "            \n", "            jsonpathlist_clean.append(\"RELATED_ORDER_KEY\")\n", "            rom_list_clean.append(\"RELATED_ORDER_KEY\")\n", "            romlen_list_clean.append(\"100000\")\n", "            \n", "    except Exception as e:    \n", "                jsonpathlist_clean=[]\n", "                rom_list_clean=[] \n", "                romlen_list_clean=[]\n", "                print(\" RELATED_ORDER_KEY not present \")\n", "                \n", "                \n", "    return df,jsonpathlist_clean,rom_list_clean,romlen_list_clean"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def addPayDFSplFields_ROM_ORDER_PAYMENT_STG0(df):\n", "    \n", "    \n", "    \n", "         try:\n", "            \n", "            df=df.withColumn(\"PAYMENT_ACCT_NO\", lit(None))\n", "         except Exception as e:\n", "            \n", "            print(e)\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["         try:\n", "            \n", "            \n", "            df.select(\"order_paymentMethods.code\",\"order_paymentMethods.creditCardNumber\")     \n", "            df=df.withColumn(\"PAYMENT_ACCT_NO\", when(col(\"order_paymentMethods.code\") == \"CREDIT_CARD\",col(\"order_paymentMethods.creditCardNumber\") )      \n", "                     .otherwise(None))\n", "            \n", "         except Exception as e:\n", "            \n", "            print(e)\n", "         try:\n", "            \n", "            \n", "            df.select(\"order_paymentMethods.code\",\"order_paymentMethods.payPalNumber\")     \n", "            df=df.withColumn(\"PAYMENT_ACCT_NO\", when(col(\"order_paymentMethods.code\") == \"PAYPAL\",col(\"order_paymentMethods.payPalNumber\") )      \n", "                     .otherwise(col(\"PAYMENT_ACCT_NO\")))\n", "            \n", "         except Exception as e:\n", "            \n", "            print(e)\n", "            \n", "            \n", "         try:\n", "            \n", "            \n", "            df.select(\"order_paymentMethods.code\",\"order_paymentMethods.storedValueCardNumber\")     \n", "            df=df.withColumn(\"PAYMENT_ACCT_NO\", when(col(\"order_paymentMethods.code\") == \"STORED_VALUE_CARD\",col(\"order_paymentMethods.storedValueCardNumber\") )      \n", "                     .otherwise(col(\"PAYMENT_ACCT_NO\")))\n", "            \n", "         except Exception as e:\n", "            \n", "            print(e)\n", "            \n", "            \n", "         try:\n", "            \n", "            \n", "            df.select(\"order_paymentMethods.code\",\"order_paymentMethods.storedValueCardNumber\")     \n", "            df=df.withColumn(\"PAYMENT_ACCT_NO\", when(col(\"order_paymentMethods.code\") == \"PREPAID_CARD\",None)\n", "                 .otherwise(col(\"PAYMENT_ACCT_NO\")))\n", "            \n", "         except Exception as e:\n", "            \n", "            print(e)\n", "        \n", "        \n", "        \n", "        #try:\n", "            \n", "            \n", "            #df = df.withColumn(\"PAYMENT_ACCT_NO\", when(col(\"order_paymentMethods.code\") == \"CREDIT_CARD\",col(\"order_paymentMethods.creditCardNumber\") )      \n", "                     #.when(col(\"order_paymentMethods.code\") == \"PAYPAL\",col(\"order_paymentMethods.payPalNumber\")) \n", "                     #.when(col(\"order_paymentMethods.code\") == \"STORED_VALUE_CARD\",col(\"order_paymentMethods.storedValueCardNumber\"))\n", "                     #.when(col(\"order_paymentMethods.code\") == \"PREPAID_CARD\",None )\n", "                     #.otherwise(None))\n", "            \n", "        #except Exception as e:\n", "            \n", "            #print(\"PAYMENT_ACCT_NO not found\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["         try:\n", "        \n", "           ## OrderId + tenderType + AccountNo  ## AccountNo - verify Mapping \n", "           df = df.withColumn(\"PAYMENT_KEY\", concat_ws('',col(\"order.id\"), lit(\"-\"), col(\"order_paymentMethods.tenderType\"), \n", "                            lit(\"-\"),  col(\"PAYMENT_ACCT_NO\")))\n", "                            \n", "           # jsonpathlist_clean.append(\"PAYMENT_KEY\")\n", "           # rom_list_clean.append(\"PAYMENT_KEY\")\n", "           # romlen_list_clean.append(\"100000\")  \n", "           \n", "           #df.select(\"order_paymentMethods.code\",\"PAYMENT_KEY\").show() \n", "         except Exception as e:\n", "              \n", "            print(\"PAYMENT_KEY not found\")\n", "            print(e)   \n", "                                                    \n", "                                                    \n", "                                                    \n", "         return df\n", "     \n", "        \n", "     \n", "def updateDFSplFields_ROM_ORDER_PAYMENT_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n", "    \n", "    \n", "    \n", "         try:\n", "            \n", " \n", "            df.select(\"PAYMENT_ACCT_NO\")\n", "            jsonpathlist_clean.append(\"PAYMENT_ACCT_NO\")\n", "            rom_list_clean.append(\"PAYMENT_ACCT_NO\")\n", "            romlen_list_clean.append(\"100000\")  \n", "            \n", "         except Exception as e:\n", "            \n", "            print(e)\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["         try:\n", "        \n", "           df.select(\"PAYMENT_KEY\")\n", "           jsonpathlist_clean.append(\"PAYMENT_KEY\")\n", "           rom_list_clean.append(\"PAYMENT_KEY\")\n", "           romlen_list_clean.append(\"100000\")  \n", "           \n", "           #df.select(\"order_paymentMethods.code\",\"PAYMENT_KEY\").show() \n", "         except Exception as e:\n", "              \n", "            print(\"PAYMENT_KEY not found\")\n", "            print(e)   \n", "                                                    \n", "                                                    \n", "                                                    \n", "         return df, jsonpathlist_clean,rom_list_clean,romlen_list_clean        \n", "                                     \n", "                                     \n", "    \n", "def updateDFSplFields_ROM_ORDER_PROMOTION_STG0( df,jsonpathlist_clean,rom_list_clean,romlen_list_clean ):"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["       try:   \n", "            \n", "           df.select(\"order.id\",\"order_lineItems.lineNo\",\"order_lineItems_sublineItems.sublineNo\",\"order_lineItems_charges.id\",\"order_lineItems_charges_discounts.id\")                                          \n", "           ### OrderId + LineNo + SubLineNo + ChargeId + DiscountsId\n", "           df = df.withColumn(\"PROMOTION_KEY\", concat(col(\"order.id\"), lit(\"-\"), col(\"order_lineItems.lineNo\"), \n", "                 lit(\"-\"),  col(\"order_lineItems_sublineItems.sublineNo\"),  lit(\"-\"), col(\"order_lineItems_charges.id\"),\n", "                 lit(\"-\"),  col(\"order_lineItems_charges_discounts.id\")    ))  \n", "                                                    \n", "           jsonpathlist_clean.append(\"PROMOTION_KEY\")\n", "           rom_list_clean.append(\"PROMOTION_KEY\")    \n", "           romlen_list_clean.append(\"100000\") \n", "                                                    \n", "       except Exception as e:\n", "            jsonpathlist_clean=[]\n", "            rom_list_clean=[] \n", "            print(e) \n", "            print(\"PROMOTION_KEY not found\")\n", "            \n", "                                   \n", "       #print(jsonpathlist_clean)  \n", "    \n", "                                                    \n", "       if \"PROMOTION_KEY\" in jsonpathlist_clean: \n", "        \n", "        try: \n", "            \n", "           df.select(\"*\",\"order_lineItems_charges_discounts.customAttributes.name\",\"order_lineItems_charges_discounts.customAttributes.value\") \n", "                                                    \n", "           try:\n", "            \n", "                df.select(col(\"order_lineItems_charges_discounts.customAttributes.name\").getItem(0))\n", "                df.select(col(\"order_lineItems_charges_discounts.customAttributes.value\").getItem(0))\n", "                df.select(col(\"order_lineItems_charges_discounts.customAttributes.name\").getItem(1))\n", "                df.select(col(\"order_lineItems_charges_discounts.customAttributes.value\").getItem(1))\n", "                df.select(col(\"order_lineItems_charges_discounts.customAttributes.name\").getItem(2))\n", "                df.select(col(\"order_lineItems_charges_discounts.customAttributes.value\").getItem(2))\n", "                \n", "                df=df.withColumn(\"PROMOTION_ID\",when(df[\"order_lineItems_charges_discounts.customAttributes.name\"].getItem(0) == \"promoCode\",\n", "                                                df[\"order_lineItems_charges_discounts.customAttributes.value\"].getItem(0))).withColumn(\"PROMOTION_DESCRIPTION\",\n", "                                 when(df[\"order_lineItems_charges_discounts.customAttributes.name\"].getItem(1) == \"promoDescription\",\n", "                                 df[\"order_lineItems_charges_discounts.customAttributes.value\"].getItem(1))).withColumn(\"PROMOTION_CODE\",\n", "                                 when(df[\"order_lineItems_charges_discounts.customAttributes.name\"].getItem(2) == \"promoId\",\n", "                                 df[\"order_lineItems_charges_discounts.customAttributes.value\"].getItem(2)))\n", "                                                                                                                        \n", "                                                                                                                        \n", "                                                                                                                        #.withColumn(\"PROMOTION_DESCRIPTION\",\n", "                                 #when(df[\"order_lineItems_charges_discounts.customAttributes.name\"].getItem(3) == \"EffectType\",\n", "                                 #df[\"order_lineItems_charges_discounts.customAttributes.value\"].getItem(3)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                jsonpathlist_clean.append(\"PROMOTION_ID\")\n", "                rom_list_clean.append(\"PROMOTION_ID\")    \n", "                romlen_list_clean.append(\"100000\") \n", "                \n", "                jsonpathlist_clean.append(\"PROMOTION_DESCRIPTION\")\n", "                rom_list_clean.append(\"PROMOTION_DESCRIPTION\")    \n", "                romlen_list_clean.append(\"100000\") \n", "                \n", "                jsonpathlist_clean.append(\"PROMOTION_CODE\")\n", "                rom_list_clean.append(\"PROMOTION_CODE\")    \n", "                romlen_list_clean.append(\"100000\") \n", "            \n", "           except Exception as e:\n", "               \n", "               print(\"PROMOTION details not retrieved\")\n", "               #print(e)\n", "                                                    \n", "                                                    \n", "        except Exception as e:\n", "               \n", "               print(\" Can't retrieve Promotion Custom Attributes\")\n", "               #print(e)\n", "                                                    \n", "                    \n", "       return df,jsonpathlist_clean,rom_list_clean,romlen_list_clean       \n", "    \n", "         \n", "def updateDFSplFields_ROM_ORDER_REFERENCES_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n", "    \n", "    \n", "           dft = spark.createDataFrame([], StructType([]))\n", "           dft1 = spark.createDataFrame([], StructType([]))\n", "           dft2 = spark.createDataFrame([], StructType([]))\n", "           dft3 = spark.createDataFrame([], StructType([]))\n", "           dft4 = spark.createDataFrame([], StructType([]))\n", "            \n", "           dfarr=[]\n", "           \n", "           \n", "           print(\"HERE......................................................\")\n", "           \n", "    \n", "           try:\n", "               \n", "               dfexp = df.withColumn(\"order_customAttributes\",explode(\"order.customAttributes\"))\n", "                \n", "               if dfexp.rdd.isEmpty():\n", "                   \n", "                   print(\"ORDER Custom Attributes Empty\")\n", "                   print(dfexp.rdd.isEmpty)\n", "                    \n", "               else:\n", "                \n", "                   dft = dfexp.withColumn(\"REFERENCE_TYPE\", lit(\"ORDER\"))\n", "                   #dft = dft.withColumn(\"REFERENCE_KEY\", col(\"order.id\"))\n", "                   dft = dft.withColumn(\"REFERENCE_KEY\", concat(col(\"order.sellerId\"), lit(\"-\"), col(\"order.id\")))\n", "                   dft = dft.withColumn(\"ATTRIB_NAME\", col(\"order_customAttributes.name\"))\n", "                   dft = dft.withColumn(\"ATTRIB_VALUE\", col(\"order_customAttributes.value\"))\n", "                   dft = dft.drop(\"order_customAttributes\")\n", "                   dfarr.append(dft)\n", "                    \n", "                   print(\"AT ORDER\")\n", "                \n", "                \n", "                                                    \n", "           except Exception as e:\n", "                                                    \n", "                  print(e)  \n", "                              \n", "                        \n", "           try:\n", "            \n", "               dfexp = df.withColumn(\"order_charges_customAttributes\",explode(\"order_charges.customAttributes\"))\n", "                \n", "               if dfexp.rdd.isEmpty():\n", "                   \n", "                   print(\"CHARGES Custom Attributes Empty\")\n", "                   print(dfexp.rdd.isEmpty)\n", "                    \n", "               else:\n", "                \n", "                   dft1 = dfexp.withColumn(\"REFERENCE_TYPE\", lit(\"CHARGES\"))\n", "                   dft1 = dft1.withColumn(\"REFERENCE_KEY\", col(\"order.id\"))\n", "                   dft1 = dft1.withColumn(\"ATTRIB_NAME\", col(\"order_charges_customAttributes.name\"))\n", "                   dft1 = dft1.withColumn(\"ATTRIB_VALUE\", col(\"order_charges_customAttributes.value\")) \n", "                   dft1 = dft1.drop(\"order_charges_customAttributes\")\n", "                   dfarr.append(dft1)\n", "                    \n", "                   print(\"AT CHARGES\")\n", "                                                                    \n", "           except Exception as e:\n", "                  \n", "                  print(\"Can't find CHARGES\")\n", "                  #print(e)\n", "                                                    \n", "           try:\n", "                                                    \n", "               dfexp = df.withColumn(\"order_lineItems_customAttributes\",explode(\"order_lineItems.customAttributes\"))\n", "                \n", "               if dfexp.rdd.isEmpty():\n", "                  \n", "                   print(\"LINE Custom Attributes Empty\")\n", "                   print(dfexp.rdd.isEmpty)\n", "                    \n", "               else:\n", "                \n", "                   dft2 = dfexp.withColumn(\"REFERENCE_TYPE\", lit(\"LINE\"))\n", "                   #dft2 = dft2.withColumn(\"REFERENCE_KEY\", col(\"order.id\"))\n", "                   dft2 = dft2.withColumn(\"REFERENCE_KEY\", concat(col(\"order.sellerId\"), lit(\"-\"), col(\"order.id\"), lit(\"-\"), col(\"order_lineItems.lineNo\") ))\n", "                   dft2 = dft2.withColumn(\"ATTRIB_NAME\", col(\"order_lineItems_customAttributes.name\"))\n", "                   dft2 = dft2.withColumn(\"ATTRIB_VALUE\", col(\"order_lineItems_customAttributes.value\")) \n", "                   dft2 = dft2.drop(\"order_lineItems_customAttributes\")\n", "                   dfarr.append(dft2)\n", "                   print(\"********\")\n", "                   print(dft2.columns) \n", "                   print(\"AT LINE\")\n", "                   print(\"********\")\n", "                \n", "                                                    \n", "           except Exception as e:\n", "                  \n", "                  print(\"Can't find LINE\")\n", "                  #print(e)\n", "                                                    \n", "            \n", "           try:\n", "            \n", "               dfexp = df.withColumn(\"order_lineItems_charges_customAttributes\",explode(\"order_lineItems_charges.customAttributes\"))\n", "            \n", "               if dfexp.rdd.isEmpty():\n", "                   \n", "                   print(\"LINE_CHARGES Custom Attributes Empty\")\n", "                   print(dfexp.rdd.isEmpty)\n", "                    \n", "               else:\n", "                  \n", "                   dft3 = dfexp.withColumn(\"REFERENCE_TYPE\", lit(\"LINE_CHARGES\"))\n", "                   #dft3 = dft3.withColumn(\"REFERENCE_KEY\", col(\"order.id\"))\n", "                   dft3 = dft3.withColumn(\"REFERENCE_KEY\", concat(col(\"order.id\"), lit(\"-\"),  col(\"order_lineItems.lineNo\"),\n", "                   lit(\"-\"),  col(\"order_lineItems_sublineItems.sublineNo\"),\n", "                   lit(\"-\"),  col(\"order_lineItems_charges.id\"),\n", "                   lit(\"-\"),  col(\"order_lineItems_charges_discounts.id\") )) \n", "                   dft3 = dft3.withColumn(\"ATTRIB_NAME\", col(\"order_lineItems_charges.customAttributes.name\"))\n", "                   dft3 = dft3.withColumn(\"ATTRIB_VALUE\", col(\"order_lineItems_charges.customAttributes.value\")) \n", "                   dft3 = dft3.drop(\"order_lineItems_charges_customAttributes\")\n", "                   #dft3 = dft3.drop(\"customAttributes\")\n", "                   dfarr.append(dft3)\n", "                    \n", "                   print(\"AT LINE_CHARGES\") \n", "               \n", "                                                    \n", "           except Exception as e:\n", "            \n", "                  print(\"Can't find LINE_CHARGES\")\n", "                                                    \n", "                  #print(e)\n", "                                                    \n", "            \n", "           try:\n", "               dfexp = df.withColumn(\"order_paymentMethods_customAttributes\",explode(\"order_paymentMethods.customAttributes\"))\n", "            \n", "               if dfexp.rdd.isEmpty():\n", "                   \n", "                   print(\"PAYMENT Custom Attributes Empty\")\n", "                   print(dfexp.rdd.isEmpty)\n", "                    \n", "               else:\n", "                \n", "                   dft4=dfexp.withColumn(\"REFERENCE_TYPE\", lit(\"PAYMENT\"))\n", "                   #dft4 = dft4.withColumn(\"REFERENCE_KEY\", col(\"order.id\"))\n", "                   dft4 = dft4.withColumn(\"REFERENCE_KEY\", concat_ws('',col(\"order.id\"), lit(\"-\"), col(\"order_paymentMethods.tenderType\"), \n", "                            lit(\"-\"),  col(\"PAYMENT_ACCT_NO\")))\n", "                   dft4 = dft4.withColumn(\"ATTRIB_NAME\", col(\"order_paymentMethods_customAttributes.name\"))\n", "                   dft4 = dft4.withColumn(\"ATTRIB_VALUE\", col(\"order_paymentMethods_customAttributes.value\")) \n", "                   dft4 = dft4.drop(\"order_paymentMethods_customAttributes\")\n", "                   dfarr.append(dft4)\n", "                    \n", "                   print(\"AT PAYMENT\") \n", "                    \n", "                                                    \n", "           except Exception as e:\n", "                  \n", "                  print(\"Can't find PAYMENT\")\n", "                  #print(e)    \n", "                    \n", "                    \n", "           try: \n", "               \n", "               print(\"Length of DFARR...........\")\n", "               print(len(dfarr))\n", "               if dfarr:\n", "                 \n", "                  for dfe in dfarr[1:]:\n", "                    \n", "                        #dfe.select(\"REFERENCE_TYPE\", \"REFERENCE_KEY\").show(2)\n", "                        \n", "                        #print(dft.columns)\n", "                        print(\"==========================\")\n", "                        #print(dfe.columns)\n", "                    \n", "                        dft = dft.union(dfe)\n", "                \n", "                  df=dft\n", "                    \n", "                  jsonpathlist_clean.append(\"REFERENCE_KEY\")\n", "                  rom_list_clean.append(\"REFERENCE_KEY\")    \n", "                  romlen_list_clean.append(\"100000\")   \n", "                \n", "                  jsonpathlist_clean.append(\"REFERENCE_TYPE\")\n", "                  rom_list_clean.append(\"REFERENCE_TYPE\")    \n", "                  romlen_list_clean.append(\"100000\")\n", "                  \n", "                  jsonpathlist_clean.append(\"ATTRIB_NAME\")\n", "                  rom_list_clean.append(\"ATTRIB_NAME\")    \n", "                  romlen_list_clean.append(\"100000\")   \n", "                \n", "                  jsonpathlist_clean.append(\"ATTRIB_VALUE\")\n", "                  rom_list_clean.append(\"ATTRIB_VALUE\")    \n", "                  romlen_list_clean.append(\"100000\")\n", "                    \n", "           except Exception as e:\n", "                  \n", "                  print(\"Error during union\")                                  \n", "                  print(e)\n", "                    \n", "                \n", "           return df,jsonpathlist_clean,rom_list_clean,romlen_list_clean\n", "                                                    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def updateDFSplFields_ROM_ORDER_TAX_BREAKUP_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n", "    \n", "    try:                                            \n", "                                                    \n", "           ### TAX_BREAKUP_KEY: OrderId + LineNo + SubLineNo + ChargeId + DiscountsId + TaxSequence \n", "           ### Need to check on Tax Sequence.   \n", "           #df.select(\"order.id\",\"order_lineItems.lineNo\",\"order_lineItems_sublineItems.sublineNo\",\"order_lineItems_charges.id\",\"order_lineItems_charges_discounts.id\",\"TaxSequence\")\n", "           df.select(\"order.id\",\"order_lineItems.lineNo\",\"order_lineItems_sublineItems.sublineNo\",\"order_lineItems_charges.id\",\"order_lineItems_charges_discounts.id\")\n", "           #df = df.withColumn(\"TAX_BREAKUP_KEY\", concat(col(\"order.id\"), lit(\"-\"), col(\"order_lineItems.lineNo\"), \n", "           #      lit(\"-\"),  col(\"order_lineItems_sublineItems.sublineNo\"),  lit(\"-\"), col(\"order_lineItems_charges.id\"),\n", "           #      lit(\"-\"),  col(\"order_lineItems_charges_discounts.id\"), lit(\"-\"),col(\"TaxSequence\")    ))  \n", "           df = df.withColumn(\"TAX_BREAKUP_KEY\", concat(col(\"order.id\"), lit(\"-\"), col(\"order_lineItems.lineNo\"), \n", "                 lit(\"-\"),  col(\"order_lineItems_sublineItems.sublineNo\"),  lit(\"-\"), col(\"order_lineItems_charges.id\"),\n", "                 lit(\"-\"),  col(\"order_lineItems_charges_discounts.id\") ))                                          \n", "           jsonpathlist_clean.append(\"TAX_BREAKUP_KEY\")\n", "           rom_list_clean.append(\"TAX_BREAKUP_KEY\")  \n", "           romlen_list_clean.append(\"100000\") \n", "                                                    \n", "    except Exception as e:\n", "              \n", "            print(\"TAX_BREAKUP_KEY not found\")\n", "            #print(e)   \n", "            \n", "            \n", "    return df,jsonpathlist_clean,rom_list_clean,romlen_list_clean"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    \n", "def updateDFSplFields_ROM_ORDER_LINE_RELATIONSHIP_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n", "    \n", "    try:                                                 \n", "             \n", "           ### RELATED_ORDER_KEY: SellerId + OrderId + RelType + ParentLineNo + ChileLineNo\n", "           df.select(\"order.sellerId\",\"order.id\",\"order_relatedOrders.type\",\"order_lineItems.lineNo\",\"order_relatedOrders_relatedLines.lineNo\")\n", "           df = df.withColumn(\"RELATED_ORDER_KEY\", concat(col(\"order.sellerId\"), lit(\"-\"), col(\"order.id\"), \n", "                 lit(\"-\"),  col(\"order_relatedOrders.type\"),  lit(\"-\"), col(\"order_lineItems.lineNo\"),\n", "                 lit(\"-\"),  col(\"order_relatedOrders_relatedLines.lineNo\") ))  \n", "                                                    \n", "           jsonpathlist_clean.append(\"RELATED_ORDER_KEY\")\n", "           rom_list_clean.append(\"RELATED_ORDER_KEY\")    \n", "           romlen_list_clean.append(\"100000\") \n", "                                                    \n", "    except Exception as e:\n", "            jsonpathlist_clean = []\n", "            rom_list_clean = []\n", "            romlen_list_clean = []\n", "            print(\"RELATED_ORDER_KEY not found\")\n", "            #print(e)  \n", "            \n", "    return df, jsonpathlist_clean,rom_list_clean,romlen_list_clean"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def updateDFSplFields_ROM_ORDER_LINE_CHARGES_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n", "    \n", "           try:   \n", "                                                    \n", "            ### LINE_CHARGES_KEY:  OrderId + LineNo + SubLineNo + ChargeId + DiscountsId\n", "            df.select(\"order.id\",\"order_lineItems.lineNo\",\"order_lineItems_sublineItems.sublineNo\",\"order_lineItems_charges.id\",\"order_lineItems_charges_discounts.id\")\n", "            \n", "            df = df.withColumn(\"LINE_CHARGES_KEY\", concat(col(\"order.id\"), lit(\"-\"),  col(\"order_lineItems.lineNo\"),\n", "                 lit(\"-\"),  col(\"order_lineItems_sublineItems.sublineNo\"),\n", "                 lit(\"-\"),  col(\"order_lineItems_charges.id\"),\n", "                 lit(\"-\"),  col(\"order_lineItems_charges_discounts.id\") ))  \n", "                                                    \n", "            jsonpathlist_clean.append(\"LINE_CHARGES_KEY\")\n", "            rom_list_clean.append(\"LINE_CHARGES_KEY\")\n", "            romlen_list_clean.append(\"0\")\n", "                                                    \n", "           except Exception as e:\n", "                                                    \n", "                 print(e)    \n", "                                                    \n", "           \n", "           try:\n", "                \n", "                df.withColumn(\"order_lineItems_charges_customAttributes\", explode_outer(\"order_lineItems_charges.customAttributes\"))  \n", "                df=df.withColumn(\"order_lineItems_charges_customAttributes\", explode_outer(\"order_lineItems_charges.customAttributes\"))  \n", "                df.select(\"*\",\n", "                          \"order_lineItems_charges_customAttributes.name\",\"order_lineItems_charges_customAttributes.value\")\n", "                df=df.select(\"*\",\n", "                     \"order_lineItems_charges_customAttributes.name\",\"order_lineItems_charges_customAttributes.value\")\n", "                df=df.withColumnRenamed(\"name\",\"CHARGES_CUST_ATTR_NAME\")  \n", "                df=df.withColumnRenamed(\"value\",\"CHARGES_CUST_ATTR_VALUE\")  \n", "              \n", "                df=df.withColumn(\"REFERENCE\", when(col(\"CHARGES_CUST_ATTR_NAME\") == \"Reference\", col(\"CHARGES_CUST_ATTR_VALUE\") ) )\n", "                df=df.drop(\"CHARGES_CUST_ATTR_NAME\")\n", "                df=df.drop(\"CHARGES_CUST_ATTR_VALUE\")\n", "               \n", "                jsonpathlist_clean.append(\"REFERENCE\")\n", "                rom_list_clean.append(\"REFERENCE\")\n", "                romlen_list_clean.append(\"100000\") \n", "            \n", "           except Exception as e:\n", "                  print(\"REFERENCE ERROR...............\")\n", "                                                    \n", "                  print(e)   \n", "                                                    \n", "           try:\n", "               df.select(\"order_lineItems_charges.detail.originalChargeAmount\")\n", "               #df=df.withColumn(\"ORIGINAL_CHARGE_AMT\", col(\"order_lineItems_charges.detail.originalChargeAmount\") ) \n", "            \n", "               jsonpathlist_clean.append(\"order_lineItems_charges.detail.originalChargeAmount\")\n", "               rom_list_clean.append(\"ORIGINAL_CHARGE_AMT\")\n", "               romlen_list_clean.append(\"100000\") \n", "      \n", "           except Exception as e:\n", "                         \n", "                 try:\n", "                      \n", "                     df.select(\"order_lineItems_charges.detail.amount\")\n", "                     #df=df.withColumn(\"ORIGINAL_CHARGE_AMT\", col(\"order_lineItems_charges.detail.amount\") ) \n", "                     jsonpathlist_clean.append(\"order_lineItems_charges.detail.amount\")\n", "                     rom_list_clean.append(\"ORIGINAL_CHARGE_AMT\")\n", "                     romlen_list_clean.append(\"100000\") \n", "                 except Exception as e:\n", "                           \n", "                           print(\"ORIGINAL_CHARGE_AMT not found....\")                         \n", "                           print(e)\n", "                                                    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["           return df, jsonpathlist_clean,rom_list_clean,romlen_list_clean"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def updateDFSplFields_ROM_ORDER_LINE_STATUS_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n", "    \n", "    \n", "       try:\n", "          df.select(\"order.sellerId\", \"order.id\", \"order_lineItems_sublineItems.sublineNo\" )\n", "          df = df.withColumn(\"ORDER_LINE_STATUS_KEY\", concat(col(\"order.sellerId\"), lit(\"-\"),  col(\"order.id\"),\n", "                 lit(\"-\"),  col(\"order_lineItems_sublineItems.sublineNo\") ))                                           \n", "                                                    \n", "          jsonpathlist_clean.append(\"ORDER_LINE_STATUS_KEY\")\n", "          rom_list_clean.append(\"ORDER_LINE_STATUS_KEY\") \n", "          romlen_list_clean.append(\"100000\")  \n", "          \n", "          \n", "       except Exception as e:\n", "                           \n", "                           print(\"ORDER_LINE_STATUS_KEY not found....\")                         \n", "                           print(e)\n", "            \n", "            \n", "       return df, jsonpathlist_clean,rom_list_clean,romlen_list_clean\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    \n", "######## Update Special Fields in the Tables #########    \n", "    \n", "def updateDFSplFields(df,tbl,jsonpathlist_clean,rom_list_clean,romlen_list_clean, conn):\n", "     \n", "    \n", "    \n", "    if ( tbl ==  \"KAFKARADIAL.ROM_ORDER_HEADER_STG0\" ):\n", "        \n", "       print(\"Accessing Special Fields from \"+tbl) \n", "       insertLogs(\"INFO\",\"Accessing Special Fields from \"+tbl, conn) \n", "        \n", "       df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_HEADER_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)\n", "                    \n", "        \n", "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_LINE_STG0\" ):\n", "        \n", "        print(\"Accessing Special Fields from \"+tbl) \n", "        insertLogs(\"INFO\",\"Accessing Special Fields from \"+tbl, conn) \n", "        \n", "        df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_LINE_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)\n", "        \n", "        \n", "    elif ( tbl == \"KAFKARADIAL.ROM_RELATED_ORDERS_STG0\" ):\n", "        \n", "        print(\"Accessing Special Fields from \"+tbl) \n", "        insertLogs(\"INFO\",\"Accessing Special Fields from \"+tbl, conn) \n", "        \n", "        df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_RELATED_ORDERS_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)\n", "                \n", "        \n", "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_PAYMENT_STG0\" ): \n", "        \n", "        print(\"Accessing Special Fields from \"+tbl) \n", "        insertLogs(\"INFO\",\"Accessing Special Fields from \"+tbl, conn) \n", "        \n", "        df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_PAYMENT_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)                              \n", "                                                         \n", "    \n", "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_PROMOTION_STG0\" ):  \n", "        \n", "        print(\"Accessing Special Fields from \"+tbl) \n", "        insertLogs(\"INFO\",\"Accessing Special Fields from \"+tbl, conn) \n", "        \n", "        df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_PROMOTION_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)\n", "                                                    \n", "    \n", "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_REFERENCES_STG0\" ): \n", "        \n", "        print(\"Accessing Special Fields from \"+tbl) \n", "        insertLogs(\"INFO\",\"Accessing Special Fields from \"+tbl, conn) \n", "                                                    \n", "        df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_REFERENCES_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)\n", "                                                    \n", "                                                 \n", "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_TAX_BREAKUP_STG0\" ):\n", "        \n", "        print(\"Accessing Special Fields from \"+tbl) \n", "        insertLogs(\"INFO\",\"Accessing Special Fields from \"+tbl, conn) \n", "                                                 \n", "        df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_TAX_BREAKUP_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)                                        \n", "                                                    \n", "                                                 \n", "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_LINE_RELATIONSHIP_STG0\" ):\n", "        \n", "         print(\"Accessing Special Fields from \"+tbl) \n", "         insertLogs(\"INFO\",\"Accessing Special Fields from \"+tbl, conn) \n", "         \n", "         df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_LINE_RELATIONSHIP_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)                                    \n", "                                                 \n", "    elif ( tbl == \"KAFKARADIAL.ROM_ORDER_CUSTOMER_INFO_STG0\" ):\n", "        \n", "            print(\"Accessing Special Fields from \"+tbl) \n", "            insertLogs(\"INFO\",\"Accessing Special Fields from \"+tbl, conn) \n", "            print(\"No Special Fields\")\n", "                                                 \n", "    elif  ( tbl == \"KAFKARADIAL.ROM_ORDER_LINE_CHARGES_STG0\" ):  \n", "        \n", "          print(\"Accessing Special Fields from \"+tbl) \n", "          insertLogs(\"INFO\",\"Accessing Special Fields from \"+tbl, conn) \n", "                                                    \n", "          df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_LINE_CHARGES_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)\n", "                                                 \n", "    elif  ( tbl == \"KAFKARADIAL.ROM_ORDER_LINE_STATUS_STG0\" ):\n", "        \n", "          print(\"Accessing Special Fields from \"+tbl) \n", "          insertLogs(\"INFO\",\"Accessing Special Fields from \"+tbl, conn) \n", "                                                 \n", "          df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields_ROM_ORDER_LINE_STATUS_STG0(df,jsonpathlist_clean,rom_list_clean,romlen_list_clean)                                      \n", "                                                 \n", "                                                 \n", "    return df,jsonpathlist_clean,rom_list_clean,romlen_list_clean     \n", "        "]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Prepare Dataframe and Populate the DB #######"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" \n", "    \n", "def prepareDFXA(df,json_exploded_path_list,romlistfinal1,rom_col_len_list,epochId,tbl,conn):\n", "    \n", "       print(\"&&&&&&&&&&\")\n", "       #dfcnt=df.count()\n", "       #print(dfcnt)\n", "       print(\"&&&&&&&&&&\")\n", "       jsonpathlist_clean=json_exploded_path_list\n", "       rom_list_clean = romlistfinal1\n", "       romlen_list_clean = rom_col_len_list\n", "       dfbadlist=[]\n", "       \n", "       \n", "        \n", "       # for elm,colval,collen in zip(json_exploded_path_list,romlistfinal1,rom_col_len_list):\n", "        \n", "       #      try:\n", "       #        df.select(elm)\n", "       #        jsonpathlist_clean.append(elm)\n", "       #        rom_list_clean.append(colval)  \n", "       #        romlen_list_clean.append(collen)\n", "       #      except Exception as e:\n", "       #        #print(e)\n", "       #        log.warn(elm)\n", "       #        print(elm)\n", "             \n", "             \n", "       # for elm,colval,collen in zip(jsonpathlist_clean,rom_list_clean,romlen_list_clean):\n", "        \n", "       #     try:\n", "               \n", "       #       df=df.withColumn(colval, when(length(col(colval)) > collen,substring(col(colval), 1, collen )        .otherwise(col(colval))))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["       #     except Exception as e:\n", "       #       #print(e)\n", "       #       print(colval)\n", "             \n", "       print(rom_list_clean)  \n", "       insertLogs(\"INFO\",str(rom_list_clean), conn) \n", "       \n", "       \n", "       # print(\"Checking Counts......................................\")\n", "       \n", "       # print(df.count())\n", "       \n", "       # print(\"Checking Counts......................................\")\n", "             \n", "       df,jsonpathlist_clean,rom_list_clean,romlen_list_clean = updateDFSplFields(df,tbl,jsonpathlist_clean,rom_list_clean, romlen_list_clean, conn)      \n", "      \n", "       #print(\"Checking Counts after Update......................................\")\n", "       \n", "       #print(df.count())\n", "       \n", "       #print(\"Checking Counts after Update......................................\")  \n", "      \n", "       cdf=df.select(jsonpathlist_clean)\n", "       #sdf = cdf\n", "        \n", "       sdf=cdf.toDF(*rom_list_clean)\n", "         \n", "    \n", "       ######## Update Dataframe ########\n", "       print(\"Updating\")\n", "       insertLogs(\"INFO\",\"Updating DF\", conn) \n", "       sdf = updateDF(sdf,tbl)\n", "    \n", "    \n", "       ##### Remove Duplicates ########\n", "       print(\"Dropping Duplicates\")\n", "       insertLogs(\"INFO\",\"Dropping Duplicates\", conn) \n", "       #tbl_pkeys=pk_dict.get(tbl)\n", "       rom_list_dp = rom_list_clean\n", "       \n", "       if (\"DW_SOURCE_ID\" in rom_list_dp):\n", "            rom_list_dp.remove(\"DW_SOURCE_ID\")\n", "       finaldf = sdf.dropDuplicates(rom_list_dp)\n", "       #finaldf = sdf.groupby(rom_list_clean).count()\n", "       #romlistgp=rom_list_clean\n", "       #romlistgp.remove(\"DW_SOURCE_ID\")\n", "       #finaldf = sdf.groupby(rom_list_clean).count()\n", "       #finaldf=finaldf.drop(\"count\")\n", "     \n", "       # if len(finaldf.dtypes) == 0:\n", "     \n", "       #           print(\"Empty\")\n", "          \n", "       # else:\n", "           \n", "       #           finaldf1 = finaldf\n", "       #           #finaldf = finaldf.unionAll(finaldf1)\n", "       #           print(\"Replicating....\")\n", "       #           #print(finaldf.count())\n", "       #           finaldf=finaldf.withColumn(\"ORDER_ID\", func.explode(func.array_repeat(\"ORDER_ID\",4)))      \n", "        \n", "       \n", "       \n", "           \n", "       # if tbl == \"KAFKARADIAL.ROM_ORDER_TAX_BREAKUP_STG0\":\n", "                       \n", "       #      finaldf = finaldf.withColumn(\"TAX_PERCENTAGE\", func.round(finaldf[\"TAX_PERCENTAGE\"], 2))\n", "         \n", "      \n", "    \n", "       return finaldf,romlen_list_clean"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(datetime.now())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query1 = dfi     .writeStream     .outputMode(\"append\")    .option(\"checkpointLocation\", argslist[5])    .option(\"partition.assignment.strategy\", \"range\")    .foreachBatch(popTablesBlkAtomicNew)    .start()\n", "    \n", "query1.awaitTermination(int(argslist[6]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["while ( (query1.status['isDataAvailable'] == True) and (query1.status['isTriggerActive'] == True) ):\n", "    \n", "    query1.status\n", "  \n", "try:\n", " \n", "  os.remove(argslist[7])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["except Exception as e:\n", "    \n", "    print(e)\n", "    \n", "query1.stop()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query1.status"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}